{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os, sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "sys.path.append('..')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "import transform_wrappers\n",
    "sys.path.append('../dsets/mnist')\n",
    "import dset\n",
    "from model import Net, Net2c\n",
    "from util import *\n",
    "from torch import nn\n",
    "from style import *\n",
    "from captum.attr import *\n",
    "import knockout\n",
    "from attributions import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('../..')\n",
    "from acd_wooseok.acd.scores import cd, score_funcs, cd_propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define net\n",
    "class Net2c_fft(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2c_fft, self).__init__()\n",
    "        self.fc0 = nn.Linear(28*28*2, 28*28)\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.fc0(x.reshape(x.shape[0], -1))\n",
    "        x = x.reshape(-1, 1, 28, 28)\n",
    "        x = self.relu1(self.pool1(self.conv1(x)))\n",
    "        x = self.relu2(self.pool2(self.conv2_drop(self.conv2(x))))\n",
    "        x = x.reshape(-1, 320)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.logits(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def predicted_class(self, x):\n",
    "        pred = self.forward(x)\n",
    "        _, pred = pred[0].max(0)\n",
    "        return pred.item() #data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Net2c(train_loader, args, t, transformer, save_path='models/cnn_vanilla.pth'):\n",
    "    # seed\n",
    "    random.seed(13)\n",
    "    np.random.seed(13)\n",
    "    torch.manual_seed(13)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.manual_seed(13)\n",
    "\n",
    "    # model\n",
    "    model = Net2c_fft().to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            B = len(target)\n",
    "            data = t(tensor_t_augment(data, transformer)).to(device)\n",
    "            target = torch.ones(2*B, dtype=target.dtype).to(device)\n",
    "            target[B:] = 0\n",
    "            # zero grad\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * 2*B, 2*len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.data.item()), end='')\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "\n",
    "# test Net2c\n",
    "def test_Net2c(test_loader, model, t, transformer):\n",
    "    # eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # test\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(test_loader)):\n",
    "        B = len(target)\n",
    "        data = t(tensor_t_augment(data, transformer)).to(device)\n",
    "        target = torch.ones(2*B, dtype=target.dtype).to(device)\n",
    "        target[B:] = 0\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').data.item()  # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= 2*len(test_loader.dataset)\n",
    "    return test_loss, correct        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set args\n",
    "args = dset.get_args()\n",
    "args.epochs = 100\n",
    "\n",
    "# load mnist data\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.test_batch_size, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model on the fft space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "idx = 0\n",
    "band_center = np.linspace(0.15, 0.85, 10)[idx]\n",
    "band_width = 0.05\n",
    "# FFT\n",
    "t = lambda x: torch.fft(torch.stack((x, torch.zeros_like(x)),dim=4) , 2)\n",
    "transform_i = transform_wrappers.modularize(lambda x: torch.ifft(x, 2)[...,0])\n",
    "transformer = lambda x: transform_bandpass(x, band_center, band_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [52480/120000 (44%)]\tLoss: 0.000009"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train_Net2c(train_loader, args, t, transformer, save_path=opj('models/freq','net2c_' + str(idx) + str(idx) + '.pth'))\n",
    "model_t = Net2c_fft().to(device)\n",
    "model_t.load_state_dict(torch.load(opj('models/freq','net2c_' + str(idx) + str(idx) + '.pth'), map_location=device))\n",
    "# test model\n",
    "test_loss, correct = test_Net2c(test_loader, model_t, t, transformer)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "    test_loss, correct, 2*len(test_loader.dataset),\n",
    "    100. * correct / (2*len(test_loader.dataset))))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scores in fft space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model on the pixel space\n",
    "model = Net2c().to(device)\n",
    "model.load_state_dict(torch.load(opj('models/freq','net2c_' + str(idx) + '.pth'), map_location=device))\n",
    "test_loss, correct = knockout.test_Net2c(test_loader, model, transformer)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "    test_loss, correct, 2*len(test_loader.dataset),\n",
    "    100. * correct / (2*len(test_loader.dataset)))) \n",
    "m_t =  transform_wrappers.Net_with_transform(model=model, transform=transform_i).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = iter(test_loader).next()\n",
    "x = x[0:1].to(device)\n",
    "x_t = t(x).to(device)\n",
    "results1 = get_attributions(x_t, m_t, class_num=1)    \n",
    "results2 = get_attributions(x_t, model_t, class_num=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get interp scores\n",
    "attr_methods = ['IG', 'DeepLift', 'SHAP', 'CD', 'InputXGradient']\n",
    "\n",
    "# viz scores in fft space\n",
    "obs_idx = 0\n",
    "plt.figure(figsize=(16, 5),dpi=100)\n",
    "for i, name in enumerate(attr_methods):\n",
    "    interp_scores = fftshift(results1[name].squeeze())\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(interp_scores, cmap='RdBu')\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "    interp_scores = fftshift(results2[name].squeeze())\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    plt.imshow(interp_scores, cmap='RdBu')\n",
    "    plt.title(name)\n",
    "    plt.axis('off')    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(freq_band(n=28, band_center=band_center, band_width=band_width))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
