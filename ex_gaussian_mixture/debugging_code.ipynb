{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "sys.path.append('vae')\n",
    "from model import init_specific_model\n",
    "from losses import Loss, _get_log_pz_qz_prodzi_qzCx, _get_log_qz_qzi_perb\n",
    "from dset import get_dataloaders\n",
    "from training import Trainer\n",
    "from utils import *\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from sim_gaussian_mixture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.001\n",
       "1     0.173\n",
       "2     0.346\n",
       "3     0.518\n",
       "4     0.691\n",
       "5     0.863\n",
       "6     1.035\n",
       "7     1.208\n",
       "8     1.380\n",
       "9     1.552\n",
       "10    1.725\n",
       "11    1.897\n",
       "12    2.070\n",
       "13    2.242\n",
       "14    2.414\n",
       "15    2.587\n",
       "16    2.759\n",
       "17    2.931\n",
       "18    3.104\n",
       "19    3.276\n",
       "20    3.449\n",
       "21    3.621\n",
       "22    3.793\n",
       "23    3.966\n",
       "24    4.138\n",
       "25    4.310\n",
       "26    4.483\n",
       "27    4.655\n",
       "28    4.828\n",
       "29    5.000\n",
       "Name: beta, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs = [\"vary_attr0_seed=10\", \"vary_attr1_seed=10\", \"vary_beta0_seed=10\"]\n",
    "results = []\n",
    "for i in range(len(dirs)):\n",
    "    # load results\n",
    "    out_dir = opj(\"/home/ubuntu/transformation-importance/ex_gaussian_mixture/results\", dirs[i])\n",
    "    fnames = sorted(os.listdir(out_dir))\n",
    "\n",
    "    results_list = []\n",
    "    for fname in fnames:\n",
    "        if fname[-3:] == 'pkl':\n",
    "            results_list.append(pkl.load(open(opj(out_dir, fname), 'rb')))\n",
    "    results.append(pd.DataFrame(results_list))\n",
    "results[2]['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.seed = 10\n",
    "p.beta = np.round(np.linspace(1e-3, 5, 30), 3)[20]\n",
    "p.num_epochs = 100\n",
    "p.hidden_dim = 7\n",
    "p.attr = 0\n",
    "p.dirname = 'vary_beta0'\n",
    "\n",
    "# seed\n",
    "random.seed(p.seed)\n",
    "np.random.seed(p.seed)\n",
    "torch.manual_seed(p.seed)\n",
    "\n",
    "# GET DATALOADERS\n",
    "(train_loader, train_latents), (test_loader, test_latents) = define_dataloaders(p)\n",
    "\n",
    "# PREPARES MODEL\n",
    "model = init_specific_model(orig_dim=p.orig_dim, latent_dim=p.latent_dim, hidden_dim=p.hidden_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "# TRAINS\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=p.lr)\n",
    "loss_f = Loss(beta=p.beta, attr=p.attr, alpha=p.alpha, gamma=p.gamma, tc=p.tc, is_mss=True)\n",
    "trainer = Trainer(model, optimizer, loss_f, device=device)\n",
    "# trainer(train_loader, test_loader, epochs=p.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating losses and metric...\n"
     ]
    }
   ],
   "source": [
    "# calculate losses\n",
    "print('calculating losses and metric...')    \n",
    "rec_loss, kl_loss, mi_loss, tc_loss, dw_kl_loss, attr_loss = calc_losses(model, test_loader, loss_f)\n",
    "s.reconstruction_loss = rec_loss\n",
    "s.kl_normal_loss = kl_loss\n",
    "s.total_correlation = tc_loss\n",
    "s.mutual_information = mi_loss\n",
    "s.dimensionwise_kl_loss = dw_kl_loss\n",
    "if p.attr > 0:\n",
    "    s.attribution_loss = attr_loss\n",
    "s.disentanglement_metric = calc_disentangle_metric(model, test_loader).mean()\n",
    "s.net = model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = train_loader.dataset.data.shape[0]\n",
    "\n",
    "data = iter(train_loader).next().to(device)\n",
    "recon_data, latent_dist, latent_sample = model(data)\n",
    "\n",
    "batch_size, latent_dim = latent_sample.shape\n",
    "\n",
    "log_pz, log_qz, log_qzi, log_prod_qzi, log_q_zCx = _get_log_pz_qz_prodzi_qzCx(latent_sample,\n",
    "                                                                              latent_dist,\n",
    "                                                                              n_data,\n",
    "                                                                              is_mss=True)  \n",
    "\n",
    "attr_loss = 0\n",
    "log_q_zCzi = log_qz.view(batch_size, 1) - log_qzi\n",
    "\n",
    "eps_batch = 50\n",
    "eps = 0.1\n",
    "deltas = 2 * eps * torch.rand(eps_batch) - eps\n",
    "\n",
    "i = 0\n",
    "perb = torch.zeros(batch_size, latent_dim, eps_batch).to(latent_sample.device)\n",
    "perb[:,i] = deltas.view(1, eps_batch) * torch.ones(batch_size, 1)\n",
    "latent_sample_p = latent_sample.unsqueeze(2) + perb\n",
    "\n",
    "log_qz_p, log_qzi_p = _get_log_qz_qzi_perb(latent_sample_p, latent_dist, n_data, is_mss=True)\n",
    "log_q_zCzi_p = log_qz_p.view(batch_size, 1, eps_batch) - log_qzi_p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (log_q_zCzi_p - log_q_zCzi.unsqueeze(2))[:,i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.L1Loss()(diff, torch.zeros_like(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3766, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(diff).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(diff).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
