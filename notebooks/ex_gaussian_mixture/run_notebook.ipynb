{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "sys.path.append('../../src/vae')\n",
    "from model import init_specific_model\n",
    "from losses import Loss\n",
    "from dset import get_dataloaders\n",
    "from training import Trainer\n",
    "from utils import *\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sim_gaussian_mixture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.num_epochs = 100\n",
    "p.seed = 13\n",
    "p.hidden_dim = 12\n",
    "p.eps = 0.005\n",
    "p.beta = 0.0\n",
    "p.mu = 0.1\n",
    "p.lamPT = 6.9\n",
    "p.lamCI = 0\n",
    "p.dirname = 'vary_beta0'\n",
    "\n",
    "# seed\n",
    "random.seed(p.seed)\n",
    "np.random.seed(p.seed)\n",
    "torch.manual_seed(p.seed)\n",
    "\n",
    "# GET DATALOADERS\n",
    "(train_loader, train_latents), (test_loader, test_latents) = define_dataloaders(p)\n",
    "\n",
    "# PREPARES MODEL\n",
    "model = init_specific_model(orig_dim=p.orig_dim, latent_dim=p.latent_dim, hidden_dim=p.hidden_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "# TRAINS\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=p.lr)\n",
    "loss_f = Loss(beta=p.beta, mu=p.mu, lamPT=p.lamPT, lamCI=p.lamCI,\n",
    "              alpha=p.alpha, gamma=p.gamma, tc=p.tc, \n",
    "              eps=p.eps, p_batch_size=p.p_batch_size, is_mss=True)\n",
    "trainer = Trainer(model, optimizer, loss_f, device=device)\n",
    "# trainer(train_loader, test_loader, epochs=p.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(train_loader).next().to(device)\n",
    "recon_data, latent_dist, latent_sample = model(data)\n",
    "latent_output = trainer.latent_map(latent_sample, data)\n",
    "n_data = train_loader.dataset.data.shape[0]\n",
    "batch_size, latent_dim = latent_sample.shape\n",
    "loss_f(data, recon_data, latent_dist, latent_sample, n_data, latent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE TEST DATA\n",
    "data = test_loader.dataset.data.to(device)\n",
    "recon_data, latent_dist, latent_sample = model(data)\n",
    "plot_2d_latent_samples(latent_sample)\n",
    "plt.title(\"Plot of test latent samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traversals(model, data, lb=4000, ub=5000, num=10)\n",
    "plt.title(\"Plot of traversals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traversals(model, data, lb=0, ub=1000, num=1,\n",
    "                draw_data=True, draw_recon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate losses\n",
    "print('calculating losses and metric...')    \n",
    "print(calc_disentangle_metric(model, test_loader).mean().item())\n",
    "# rec_loss, kl_loss, mu_loss, mi_loss, tc_loss, dw_kl_loss, li_loss = calc_losses(model, test_loader, loss_f)\n",
    "# s.reconstruction_loss = rec_loss\n",
    "# s.kl_normal_loss = kl_loss\n",
    "# s.total_correlation = tc_loss\n",
    "# s.mutual_information = mi_loss\n",
    "# s.dimensionwise_kl_loss = dw_kl_loss\n",
    "# if p.attr > 0:\n",
    "#     s.attribution_loss = attr_loss\n",
    "# s.disentanglement_metric = calc_disentangle_metric(model, test_loader).mean()\n",
    "# s.net = model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = train_loader.dataset.data.shape[0]\n",
    "\n",
    "data = iter(train_loader).next().to(device)\n",
    "recon_data, latent_dist, latent_sample = model(data)\n",
    "\n",
    "batch_size, latent_dim = latent_sample.shape\n",
    "\n",
    "log_pz, log_qz, log_qzi, log_prod_qzi, log_q_zCx = _get_log_pz_qz_prodzi_qzCx(latent_sample,\n",
    "                                                                              latent_dist,\n",
    "                                                                              n_data,\n",
    "                                                                              is_mss=True)  \n",
    "\n",
    "attr_loss = 0\n",
    "log_q_zCzi = log_qz.view(batch_size, 1) - log_qzi\n",
    "\n",
    "eps_batch = 50\n",
    "eps = 0.1\n",
    "deltas = 2 * eps * torch.rand(eps_batch) - eps\n",
    "\n",
    "for i in range(latent_dim):\n",
    "    perb = torch.zeros(batch_size, latent_dim, eps_batch).to(latent_sample.device)\n",
    "    perb[:,i] = deltas.view(1, eps_batch) * torch.ones(batch_size, 1)\n",
    "    latent_sample_p = latent_sample.unsqueeze(2) + perb\n",
    "\n",
    "    log_qz_p, log_qzi_p = _get_log_qz_qzi_perb(latent_sample_p, latent_dist, n_data, is_mss=True)\n",
    "    log_q_zCzi_p = log_qz_p.view(batch_size, 1, eps_batch) - log_qzi_p   \n",
    "    diff = (log_q_zCzi_p - log_q_zCzi.unsqueeze(2))[:,i,:]\n",
    "    diff2 = (torch.exp(log_q_zCzi_p) - torch.exp(log_q_zCzi.unsqueeze(2)))[:,i,:]\n",
    "    attr_loss += abs(diff).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (log_q_zCzi_p - log_q_zCzi.unsqueeze(2))[:,i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.L1Loss()(diff, torch.zeros_like(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(diff).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(diff).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
