{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ex_biology import p\n",
    "from dset import get_dataloader, load_pretrained_model\n",
    "\n",
    "# adaptive-wavelets modules\n",
    "from losses import get_loss_f\n",
    "from train import Trainer\n",
    "from evaluate import Validator\n",
    "from transform1d import DWT1d\n",
    "from utils import get_1dfilts, get_wavefun, low_to_high\n",
    "from wave_attributions import Attributer\n",
    "from visualize import cshow, plot_1dfilts, plot_1dreconstruct, plot_wavefun\n",
    "\n",
    "# evaluation\n",
    "from matplotlib import gridspec\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from feature_transform import max_transformer\n",
    "\n",
    "# trim model\n",
    "from trim import TrimModel\n",
    "\n",
    "# cd\n",
    "import acd\n",
    "from acd.scores import cd_propagate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and model\n",
    "train_loader, test_loader = get_dataloader(p.data_path, \n",
    "                                           batch_size=p.batch_size,\n",
    "                                           is_continuous=p.is_continuous)   \n",
    "\n",
    "model = load_pretrained_model(p.model_path, device=device)    \n",
    "\n",
    "# wavelet transform \n",
    "wt = DWT1d(wave='db5', mode='zero', J=4, init_factor=1, noise_factor=0.0).to(device)\n",
    "\n",
    "# get a batch of images\n",
    "data = iter(test_loader).next()[0]\n",
    "data = data.to(device)\n",
    "\n",
    "# wavelet transform and reconstruction\n",
    "data_t = wt(data)\n",
    "recon = wt.inverse(data_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data / recon torch.Size([100, 1, 40]) torch.Size([100, 1, 40])\n",
      "shape of wavelet coeffs torch.Size([100, 1, 10])\n",
      "shape of wavelet coeffs torch.Size([100, 1, 24])\n",
      "shape of wavelet coeffs torch.Size([100, 1, 16])\n",
      "shape of wavelet coeffs torch.Size([100, 1, 12])\n",
      "shape of wavelet coeffs torch.Size([100, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "print('shape of data / recon', data.shape, recon.shape)\n",
    "for i in range(len(data_t)):\n",
    "    print('shape of wavelet coeffs', data_t[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 0.00000\n"
     ]
    }
   ],
   "source": [
    "print('reconstruction error: {:.5f}'.format(torch.norm(data - recon).item()/data.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8557],\n",
      "        [-0.8095],\n",
      "        [-0.4112],\n",
      "        [-0.8514],\n",
      "        [ 0.0790]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# trim model\n",
    "mt = TrimModel(model, wt.inverse, use_residuals=True).to(device)\n",
    "out = mt(data_t, deepcopy(data))\n",
    "print(out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8557],\n",
      "        [-0.8095],\n",
      "        [-0.4112],\n",
      "        [-0.8514],\n",
      "        [ 0.0790]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model(data)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate cd score in original domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.permute(0, 2, 1)\n",
    "# rel, irrel = cd_propagate.propagate_lstm(data, model.model.lstm, start=0, stop=30, my_device=device)\n",
    "# rel = rel.squeeze(1)\n",
    "# irrel = irrel.squeeze(1)\n",
    "# rel, irrel = cd_propagate.propagate_conv_linear(rel, irrel, model.model.fc)\n",
    "# rel + irrel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute cd score in wavelet domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch of images\n",
    "data = iter(test_loader).next()[0]\n",
    "data = data.to(device)\n",
    "\n",
    "# wavelet transform and reconstruction\n",
    "data_t = wt(data) # select some coefs of data_t to interpret (so maybe zero all but one coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.ones_like(recon[0:1]) # starts (batch_size, num_channels, seq_len)\n",
    "# x.data = recon[0:1]\n",
    "# x = x.permute(0, 2, 1) # should be (batch_size, seq_len, num_channels)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     rel, irrel = cd_propagate.propagate_lstm(x, model.model.lstm, start=0, stop=30, my_device=device)\n",
    "# rel = rel.squeeze(1)\n",
    "# irrel = irrel.squeeze(1)\n",
    "# rel, irrel = cd_propagate.propagate_conv_linear(rel, irrel, model.model.fc)\n",
    "# rel + irrel\n",
    "\n",
    "# x = recon\n",
    "# model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_wave_rel(x, idx):\n",
    "    l = len(x)\n",
    "    dim = [0]\n",
    "    tensor = []\n",
    "    for i in range(l):\n",
    "        d = x[i].size(2)\n",
    "        dim.append(d)\n",
    "        tensor.append(x[i])\n",
    "    tensor = torch.cat(tensor, 2)\n",
    "    rel = torch.zeros_like(tensor)\n",
    "    rel[...,idx] = tensor[...,idx]\n",
    "    irrel = tensor - rel\n",
    "    dim = list(np.cumsum(dim))\n",
    "    \n",
    "    x_rel = []\n",
    "    x_irrel = []\n",
    "    for i in range(l):\n",
    "        x_rel.append(rel[...,dim[i]:dim[i+1]])\n",
    "        x_irrel.append(irrel[...,dim[i]:dim[i+1]])\n",
    "    return tuple(x_rel), tuple(x_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = []\n",
    "for idx in range(1):\n",
    "    rel, _ = track_wave_rel(data_t, idx)\n",
    "    rel = wt.inverse(rel)\n",
    "    irrel = data - rel\n",
    "    \n",
    "    rel = rel.permute(0, 2, 1)\n",
    "    irrel = irrel.permute(0, 2, 1)    \n",
    "    \n",
    "    rel, irrel = cd_propagate.propagate_lstm_block(x_rel=rel, x_irrel=irrel,\n",
    "                                                   module=model.model.lstm,\n",
    "                                                   start=0, stop=10, my_device=device)    \n",
    "    rel = rel.squeeze(1)\n",
    "    irrel = irrel.squeeze(1)\n",
    "    rel, irrel = cd_propagate.propagate_conv_linear(rel, irrel, model.model.fc)\n",
    "    cd.append(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6547],\n",
       "        [-0.6197],\n",
       "        [-0.2235],\n",
       "        [-0.6737],\n",
       "        [ 0.0282],\n",
       "        [ 0.1258],\n",
       "        [-0.6188],\n",
       "        [ 0.3074],\n",
       "        [ 0.1007],\n",
       "        [ 0.0284],\n",
       "        [ 0.3567],\n",
       "        [-0.6164],\n",
       "        [ 0.6005],\n",
       "        [ 0.3181],\n",
       "        [ 0.2275],\n",
       "        [ 0.9623],\n",
       "        [-0.6379],\n",
       "        [ 0.0789],\n",
       "        [-0.6355],\n",
       "        [-0.1220],\n",
       "        [-0.6689],\n",
       "        [ 1.1056],\n",
       "        [-0.5101],\n",
       "        [-0.6518],\n",
       "        [-0.3684],\n",
       "        [-0.3889],\n",
       "        [-0.2986],\n",
       "        [-0.3265],\n",
       "        [ 1.0566],\n",
       "        [-0.3358],\n",
       "        [ 0.6626],\n",
       "        [-0.6092],\n",
       "        [ 0.1583],\n",
       "        [-0.6744],\n",
       "        [ 0.1731],\n",
       "        [-0.0026],\n",
       "        [-0.4538],\n",
       "        [-0.6580],\n",
       "        [-0.2977],\n",
       "        [-0.5217],\n",
       "        [-0.4511],\n",
       "        [ 0.6573],\n",
       "        [ 1.2003],\n",
       "        [ 0.4695],\n",
       "        [ 0.2023],\n",
       "        [-0.6286],\n",
       "        [-0.6472],\n",
       "        [-0.1565],\n",
       "        [-0.6102],\n",
       "        [-0.1459],\n",
       "        [-0.7757],\n",
       "        [-0.4848],\n",
       "        [-0.4929],\n",
       "        [ 0.4923],\n",
       "        [ 0.2820],\n",
       "        [-0.1710],\n",
       "        [ 0.1108],\n",
       "        [-0.1676],\n",
       "        [ 1.2037],\n",
       "        [ 1.3177],\n",
       "        [ 0.9322],\n",
       "        [-0.4946],\n",
       "        [-0.2577],\n",
       "        [-0.4556],\n",
       "        [-0.5975],\n",
       "        [-0.5314],\n",
       "        [ 0.9868],\n",
       "        [-0.5923],\n",
       "        [ 1.5707],\n",
       "        [-0.2316],\n",
       "        [-0.2698],\n",
       "        [ 2.0676],\n",
       "        [ 0.4472],\n",
       "        [-0.1067],\n",
       "        [ 0.7312],\n",
       "        [ 0.7924],\n",
       "        [-0.0677],\n",
       "        [ 0.4576],\n",
       "        [ 0.0203],\n",
       "        [ 0.0350],\n",
       "        [-0.6382],\n",
       "        [-0.6610],\n",
       "        [ 0.3503],\n",
       "        [-0.6407],\n",
       "        [-0.4832],\n",
       "        [-0.0920],\n",
       "        [-0.0875],\n",
       "        [ 0.1666],\n",
       "        [-0.5828],\n",
       "        [ 0.0719],\n",
       "        [-0.5567],\n",
       "        [-0.4489],\n",
       "        [-0.1314],\n",
       "        [-0.5645],\n",
       "        [-0.0340],\n",
       "        [-0.6303],\n",
       "        [ 0.8971],\n",
       "        [-0.6658],\n",
       "        [ 1.6646],\n",
       "        [ 0.1710]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel + irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd score tensor([[-6.2875e-01],\n",
      "        [-6.6938e-01],\n",
      "        [-2.5597e-01],\n",
      "        [-6.6279e-01],\n",
      "        [ 1.2557e-01],\n",
      "        [ 7.1962e-01],\n",
      "        [-6.3370e-01],\n",
      "        [ 5.2765e-01],\n",
      "        [ 1.7939e-01],\n",
      "        [ 7.7513e-03],\n",
      "        [ 4.9782e-01],\n",
      "        [-6.7419e-01],\n",
      "        [ 1.1866e+00],\n",
      "        [ 4.2525e-01],\n",
      "        [ 1.7598e-01],\n",
      "        [ 1.4416e+00],\n",
      "        [-4.6629e-01],\n",
      "        [ 1.2258e-01],\n",
      "        [-6.6849e-01],\n",
      "        [ 1.0506e-01],\n",
      "        [-6.0307e-01],\n",
      "        [ 1.9166e+00],\n",
      "        [ 3.2136e-03],\n",
      "        [-5.7529e-01],\n",
      "        [-4.2015e-01],\n",
      "        [ 7.3039e-03],\n",
      "        [-2.6258e-01],\n",
      "        [-7.7889e-03],\n",
      "        [ 1.3842e+00],\n",
      "        [-3.6915e-01],\n",
      "        [ 5.3586e-01],\n",
      "        [-9.8854e-02],\n",
      "        [ 1.3889e-01],\n",
      "        [-6.5502e-01],\n",
      "        [ 2.2923e-01],\n",
      "        [-1.3928e-03],\n",
      "        [ 2.5419e-02],\n",
      "        [-6.6141e-01],\n",
      "        [ 2.9942e-01],\n",
      "        [-4.7287e-01],\n",
      "        [ 4.7872e-02],\n",
      "        [ 1.0815e+00],\n",
      "        [ 1.5550e+00],\n",
      "        [ 5.1103e-01],\n",
      "        [ 5.6457e-01],\n",
      "        [-1.3829e-01],\n",
      "        [-6.6459e-01],\n",
      "        [ 2.2243e-01],\n",
      "        [-6.4199e-01],\n",
      "        [ 3.2076e-01],\n",
      "        [ 1.7163e-01],\n",
      "        [-3.7405e-01],\n",
      "        [-3.6621e-01],\n",
      "        [ 1.1116e+00],\n",
      "        [ 9.6130e-01],\n",
      "        [-2.1787e-01],\n",
      "        [ 2.4839e-01],\n",
      "        [ 3.5844e-01],\n",
      "        [ 1.4767e+00],\n",
      "        [ 1.4296e+00],\n",
      "        [ 1.3614e+00],\n",
      "        [-5.7291e-01],\n",
      "        [ 5.0446e-01],\n",
      "        [-4.6761e-01],\n",
      "        [-6.5811e-02],\n",
      "        [-2.6112e-01],\n",
      "        [ 1.4995e+00],\n",
      "        [ 1.7342e-01],\n",
      "        [ 1.9753e+00],\n",
      "        [ 6.9177e-01],\n",
      "        [ 5.6461e-02],\n",
      "        [ 2.2368e+00],\n",
      "        [ 4.7007e-01],\n",
      "        [-1.8075e-01],\n",
      "        [ 8.9259e-01],\n",
      "        [ 1.2980e+00],\n",
      "        [ 5.0782e-01],\n",
      "        [ 9.6123e-01],\n",
      "        [ 4.2514e-01],\n",
      "        [ 4.8565e-01],\n",
      "        [-6.6438e-01],\n",
      "        [-6.6182e-01],\n",
      "        [ 4.8214e-01],\n",
      "        [-6.6314e-01],\n",
      "        [-3.8961e-01],\n",
      "        [ 3.8050e-01],\n",
      "        [ 3.4810e-01],\n",
      "        [ 1.9341e-01],\n",
      "        [-4.5263e-01],\n",
      "        [ 4.1666e-01],\n",
      "        [-5.5945e-01],\n",
      "        [-9.5094e-02],\n",
      "        [-1.9265e-01],\n",
      "        [-3.5712e-01],\n",
      "        [-2.8718e-03],\n",
      "        [-6.5086e-01],\n",
      "        [ 1.5203e+00],\n",
      "        [-6.4599e-01],\n",
      "        [ 1.7805e+00],\n",
      "        [ 5.4395e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# rel, irrel (residuals shoul be put into irrel)\n",
    "\n",
    "rel, irrel = cd_propagate.propagate_lstm_block(x_rel=rel, x_irrel=irrel,\n",
    "                                               module=model.model.lstm,\n",
    "                                               start=0, stop=10, my_device=device)\n",
    "rel = rel.squeeze(1)\n",
    "irrel = irrel.squeeze(1)\n",
    "rel, irrel = cd_propagate.propagate_conv_linear(rel, irrel, model.model.fc)\n",
    "print('cd score', rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt.h0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = rel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[242.6617, 371.2155, 396.1845, 212.0899,  63.1081,  61.0499,  43.7076,\n",
       "            8.9517,  -0.3973,  -8.5035]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt.h0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
