{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import util\n",
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import cifar10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# load data \n",
    "data_path = \"../../data/cifar10\"\n",
    "train_loader, test_loader = cifar10.get_dataloader(data_path, batch_size=100, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.fc1 = nn.Linear(500, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# define model and hyperparms\n",
    "net = Net().to(device)    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [45000/50000 (90%)]\tLoss: 1.342292\n",
      "Test set: Average loss: 0.0001, Accuracy: 4942/10000 (49.42%)\n",
      "\n",
      "Train Epoch: 2 [45000/50000 (90%)]\tLoss: 1.463521\n",
      "Test set: Average loss: 0.0001, Accuracy: 5673/10000 (56.73%)\n",
      "\n",
      "Train Epoch: 3 [45000/50000 (90%)]\tLoss: 1.024426\n",
      "Test set: Average loss: 0.0001, Accuracy: 5973/10000 (59.73%)\n",
      "\n",
      "Train Epoch: 4 [45000/50000 (90%)]\tLoss: 0.974525\n",
      "Test set: Average loss: 0.0001, Accuracy: 6205/10000 (62.05%)\n",
      "\n",
      "Train Epoch: 5 [45000/50000 (90%)]\tLoss: 0.997485\n",
      "Test set: Average loss: 0.0001, Accuracy: 6363/10000 (63.63%)\n",
      "\n",
      "Train Epoch: 6 [45000/50000 (90%)]\tLoss: 1.134248\n",
      "Test set: Average loss: 0.0001, Accuracy: 6368/10000 (63.68%)\n",
      "\n",
      "Train Epoch: 7 [45000/50000 (90%)]\tLoss: 0.892892\n",
      "Test set: Average loss: 0.0001, Accuracy: 6519/10000 (65.19%)\n",
      "\n",
      "Train Epoch: 8 [45000/50000 (90%)]\tLoss: 0.838438\n",
      "Test set: Average loss: 0.0001, Accuracy: 6549/10000 (65.49%)\n",
      "\n",
      "Train Epoch: 9 [45000/50000 (90%)]\tLoss: 0.735643\n",
      "Test set: Average loss: 0.0001, Accuracy: 6575/10000 (65.75%)\n",
      "\n",
      "Train Epoch: 10 [45000/50000 (90%)]\tLoss: 0.614297\n",
      "Test set: Average loss: 0.0001, Accuracy: 6564/10000 (65.64%)\n",
      "\n",
      "Train Epoch: 11 [45000/50000 (90%)]\tLoss: 0.777923\n",
      "Test set: Average loss: 0.0001, Accuracy: 6593/10000 (65.93%)\n",
      "\n",
      "Train Epoch: 12 [45000/50000 (90%)]\tLoss: 0.619719\n",
      "Test set: Average loss: 0.0001, Accuracy: 6542/10000 (65.42%)\n",
      "\n",
      "Train Epoch: 13 [45000/50000 (90%)]\tLoss: 0.661203\n",
      "Test set: Average loss: 0.0001, Accuracy: 6620/10000 (66.20%)\n",
      "\n",
      "Train Epoch: 14 [45000/50000 (90%)]\tLoss: 0.681447\n",
      "Test set: Average loss: 0.0001, Accuracy: 6634/10000 (66.34%)\n",
      "\n",
      "Train Epoch: 15 [45000/50000 (90%)]\tLoss: 0.739905\n",
      "Test set: Average loss: 0.0001, Accuracy: 6630/10000 (66.30%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "util.train(net, device, train_loader, test_loader, optimizer, num_epochs, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
