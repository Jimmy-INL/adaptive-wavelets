{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "# import acd\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import argparse\n",
    "\n",
    "sys.path.append('../../lib/disentangling-vae')\n",
    "import main\n",
    "\n",
    "sys.path.append('../../src/vae')\n",
    "sys.path.append('../../src/vae/models')\n",
    "sys.path.append('../../src/dsets/images')\n",
    "from dset import get_dataloaders\n",
    "from model import init_specific_model\n",
    "from losses import get_loss_f\n",
    "from training import Trainer\n",
    "\n",
    "sys.path.append('../../lib/trim')\n",
    "# trim modules\n",
    "from trim import DecoderEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = main.parse_arguments()\n",
    "args.dataset = \"dsprites\"\n",
    "args.model_type = \"Burgess\"\n",
    "args.latent_dim = 10\n",
    "args.img_size = (1, 64, 64)\n",
    "args.rec_dist = \"bernoulli\"\n",
    "args.reg_anneal = 0\n",
    "args.beta = 0\n",
    "args.lamPT = 1\n",
    "args.lamNN = 0.1\n",
    "args.lamH = 0\n",
    "args.lamSP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p:\n",
    "    '''Parameters for Gaussian mixture simulation\n",
    "    '''\n",
    "    # parameters for generating data\n",
    "    seed = 13\n",
    "    dataset = \"dsprites\"\n",
    "    \n",
    "    # parameters for model architecture\n",
    "    model_type = \"Burgess\"\n",
    "    latent_dim = 10 \n",
    "    img_size = (1, 64, 64)\n",
    "    \n",
    "    # parameters for training\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 100\n",
    "    lr = 1e-4\n",
    "    rec_dist = \"bernoulli\"\n",
    "    reg_anneal = 0\n",
    "    num_epochs = 100\n",
    "    \n",
    "    # hyperparameters for loss\n",
    "    beta = 0.0\n",
    "    lamPT = 0.0\n",
    "    lamNN = 0.0\n",
    "    lamH = 0.0\n",
    "    lamSP = 0.0\n",
    "    \n",
    "    # parameters for exp\n",
    "    warm_start = None # which parameter to warm start with respect to\n",
    "    seq_init = 1      # value of warm_start parameter to start with respect to\n",
    "    \n",
    "    # SAVE MODEL\n",
    "    out_dir = \"/home/ubuntu/local-vae/notebooks/ex_dsprites/results\" # wooseok's setup\n",
    "#     out_dir = '/scratch/users/vision/chandan/local-vae' # chandan's setup\n",
    "    dirname = \"vary\"\n",
    "    pid = ''.join([\"%s\" % randint(0, 9) for num in range(0, 10)])\n",
    "\n",
    "    def _str(self):\n",
    "        vals = vars(p)\n",
    "        return 'beta=' + str(vals['beta']) + '_lamPT=' + str(vals['lamPT']) + '_lamNN=' + str(vals['lamNN']) + '_lamSP=' + str(vals['lamSP']) \\\n",
    "                + '_seed=' + str(vals['seed']) + '_pid=' + vals['pid']\n",
    "    \n",
    "    def _dict(self):\n",
    "        return {attr: val for (attr, val) in vars(self).items()\n",
    "                 if not attr.startswith('_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class s:\n",
    "    '''Parameters to save\n",
    "    '''\n",
    "    def _dict(self):\n",
    "        return {attr: val for (attr, val) in vars(self).items()\n",
    "                 if not attr.startswith('_')}\n",
    "    \n",
    "    \n",
    "# calculate losses\n",
    "def calc_losses(model, data_loader, loss_f):\n",
    "    \"\"\"\n",
    "    Tests the model for one epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_loader: torch.utils.data.DataLoader\n",
    "\n",
    "    loss_f: loss object\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    \"\"\"    \n",
    "    model.eval()\n",
    "    rec_loss = 0\n",
    "    kl_loss = 0\n",
    "    pt_loss = 0\n",
    "    nn_loss = 0\n",
    "    h_loss = 0\n",
    "    sp_loss = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        recon_data, latent_dist, latent_sample = model(data)\n",
    "        latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "        latent_output = latent_map(latent_sample, data)\n",
    "        _ = loss_f(data, recon_data, latent_dist, model.training, storer=None,\n",
    "                   latent_sample=latent_sample, latent_output=latent_output, n_data=None)           \n",
    "        rec_loss += loss_f.rec_loss.item()\n",
    "        kl_loss += loss_f.kl_loss.item()\n",
    "        pt_loss += loss_f.pt_loss.item() if type(loss_f.pt_loss) == torch.Tensor else 0\n",
    "        nn_loss += loss_f.nearest_neighbor_loss.item()if type(loss_f.nearest_neighbor_loss) == torch.Tensor else 0        \n",
    "        h_loss += loss_f.hessian_loss.item()if type(loss_f.hessian_loss) == torch.Tensor else 0        \n",
    "        sp_loss += loss_f.sp_loss.item()if type(loss_f.sp_loss) == torch.Tensor else 0                \n",
    "\n",
    "    n_batch = batch_idx + 1\n",
    "    rec_loss /= n_batch\n",
    "    kl_loss /= n_batch\n",
    "    pt_loss /= n_batch\n",
    "    nn_loss /= n_batch\n",
    "    h_loss /= n_batch\n",
    "    sp_loss /= n_batch\n",
    "\n",
    "    return (rec_loss, kl_loss, pt_loss, nn_loss, h_loss, sp_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arg in vars(args):\n",
    "    setattr(p, arg, getattr(args, arg))\n",
    "    \n",
    "# create dir\n",
    "out_dir = opj(p.out_dir, p.dirname)\n",
    "os.makedirs(out_dir, exist_ok=True)  \n",
    "\n",
    "# seed\n",
    "random.seed(p.seed)\n",
    "np.random.seed(p.seed)\n",
    "torch.manual_seed(p.seed)\n",
    "\n",
    "# get dataloaders\n",
    "train_loader = get_dataloaders(p.dataset,\n",
    "                               batch_size=p.train_batch_size,\n",
    "                               logger=None)\n",
    "\n",
    "# prepare model\n",
    "model = init_specific_model(model_type=p.model_type, \n",
    "                            img_size=p.img_size,\n",
    "                            latent_dim=p.latent_dim,\n",
    "                            hidden_dim=None).to(device)\n",
    "\n",
    "# train\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=p.lr)\n",
    "loss_f = get_loss_f(decoder=model.decoder, **vars(p))\n",
    "trainer = Trainer(model, optimizer, loss_f, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer(train_loader, epochs=p.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating losses and metric...\n"
     ]
    }
   ],
   "source": [
    "# calculate losses\n",
    "print('calculating losses and metric...')    \n",
    "rec_loss, kl_loss, pt_loss, nn_loss, h_loss, sp_loss = calc_losses(model, train_loader, loss_f)\n",
    "s.reconstruction_loss = rec_loss\n",
    "s.kl_normal_loss = kl_loss\n",
    "s.pt_local_independence_loss = pt_loss\n",
    "s.nearest_neighbor_loss = nn_loss\n",
    "s.hessian_loss = h_loss\n",
    "s.sparsity_loss = sp_loss\n",
    "# s.disentanglement_metric = calc_disentangle_metric(model, test_loader).mean().item()\n",
    "s.net = model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2464.6376222398544 0.009973166474891413 8.981220646673036e-06 0.03372489919032281 0.0 0.024180983006954194\n"
     ]
    }
   ],
   "source": [
    "print(s.reconstruction_loss, s.kl_normal_loss, s.pt_local_independence_loss, s.nearest_neighbor_loss, s.hessian_loss, s.sparsity_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
