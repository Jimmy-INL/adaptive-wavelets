{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sim_cosmology import p, load_dataloader_and_pretrained_model\n",
    "# adaptive-wavelets modules\n",
    "from losses import get_loss_f\n",
    "from train import Trainer\n",
    "from evaluate import Validator\n",
    "from transform2d import DWT2d\n",
    "from utils import get_1dfilts, get_2dfilts\n",
    "from wave_attributions import Attributer\n",
    "from visualize import cshow, plot_1dfilts, plot_2dfilts, plot_2dreconstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloader and model\n",
    "(train_loader, test_loader), model = load_dataloader_and_pretrained_model(p, img_size=256)\n",
    "\n",
    "# # check prediction\n",
    "# with torch.no_grad():\n",
    "#     result = {'y': [], 'pred': []}\n",
    "#     for data, params in train_loader:\n",
    "#         result['y'].append(params[:,1].detach().cpu())\n",
    "#         result['pred'].append(model(data.to(device))[:,1].detach().cpu())\n",
    "# plt.scatter(torch.cat(result['y']), torch.cat(result['pred']))\n",
    "# plt.xlabel('true param')\n",
    "# plt.ylabel('predicted param')\n",
    "# plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = im[0,0,...]\n",
    "x = x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "from matplotlib import pyplot as plt\n",
    "from pywt._doc_utils import wavedec2_keys, draw_2d_wp_basis\n",
    "\n",
    "shape = x.shape\n",
    "\n",
    "max_lev = 3       # how many levels of decomposition to draw\n",
    "label_levels = 3  # how many levels to explicitly label on the plots\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=[14, 8])\n",
    "for level in range(0, max_lev + 1):\n",
    "    if level == 0:\n",
    "        # show the original image before decomposition\n",
    "        axes[0, 0].set_axis_off()\n",
    "        axes[1, 0].imshow(x, cmap=plt.cm.gray, vmax=0.15, vmin=-0.05)\n",
    "        axes[1, 0].set_title('Image')\n",
    "        axes[1, 0].set_axis_off()\n",
    "        continue\n",
    "\n",
    "    # plot subband boundaries of a standard DWT basis\n",
    "    draw_2d_wp_basis(shape, wavedec2_keys(level), ax=axes[0, level],\n",
    "                     label_levels=label_levels)\n",
    "    axes[0, level].set_title('{} level\\ndecomposition'.format(level))\n",
    "\n",
    "    # compute the 2D DWT\n",
    "    c = pywt.wavedec2(x, 'db2', mode='periodization', level=level)\n",
    "    # normalize each coefficient array independently for better visibility\n",
    "#     c[0] /= np.abs(c[0]).max()\n",
    "#     for detail_level in range(level):\n",
    "#         c[detail_level + 1] = [d/np.abs(d).max() for d in c[detail_level + 1]]\n",
    "    # show the normalized coefficients\n",
    "    arr, slices = pywt.coeffs_to_array(c)\n",
    "    axes[1, level].imshow(arr, cmap=plt.cm.gray, vmax=0.15, vmin=-0.05)\n",
    "    axes[1, level].set_title('Coefficients\\n({} level)'.format(level))\n",
    "    axes[1, level].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image\n",
    "torch.manual_seed(p.seed)\n",
    "im = iter(test_loader).next()[0][0:64].to(device)\n",
    "\n",
    "# wavelet transform \n",
    "wt = DWT2d(wave='db5', mode='symmetric', J=5, init_factor=0, noise_factor=0.1).to(device)\n",
    "\n",
    "im_t = wt(im)\n",
    "recon = wt.inverse(im_t)\n",
    "\n",
    "print(\"Reconstruction error={:.5f}\".format(torch.norm(recon - im)**2/im.size(0)))\n",
    "\n",
    "# get 2d wavelet filters\n",
    "filt = get_2dfilts(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot original and reconstruction images\n",
    "plot_2dreconstruct(im, recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wavelet filters\n",
    "plot_2dfilts(filt, figsize=(4,4), share_min_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimize filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "params = list(wt.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.005)\n",
    "loss_f = get_loss_f(lamL1attr=10)\n",
    "trainer = Trainer(model, wt, Attributer, optimizer, loss_f, attr_methods='Saliency', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(train_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(trainer.train_losses))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"log train loss\")\n",
    "plt.title('Log-train loss vs epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_t = wt(im)\n",
    "recon = wt.inverse(im_t)\n",
    "\n",
    "print(\"Reconstruction error={:.5f}\".format(torch.norm(recon - im)**2/im.size(0)))\n",
    "\n",
    "# get 2d wavelet filters\n",
    "filt = get_2dfilts(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot original and reconstruction images\n",
    "plot_2dreconstruct(im, recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wavelet filters\n",
    "plot_2dfilts(filt, figsize=(4,4), share_min_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_v = get_loss_f(lamL1attr=1)\n",
    "\n",
    "# validator \n",
    "validator = Validator(model, wt, Attributer, loss_v, attr_methods='Saliency', device=device)\n",
    "_, rec_loss, L1attr_loss = validator(test_loader)\n",
    "\n",
    "# original wavelet transform\n",
    "wt_o = DWT2d(wave='db5', mode='symmetric', J=5, init_factor=1, noise_factor=0).to(device)\n",
    "validator_o = Validator(model, wt_o, Attributer, loss_v, attr_methods='Saliency', device=device)\n",
    "_, rec_loss_o, L1attr_loss_o = validator_o(test_loader)\n",
    "\n",
    "print(\"\\n\\n Original filter:Reconstruction Error={:.5f} L1attribution loss={:.5f} \\n Adaptive filter:Reconstruction Error={:.5f} L1attribution loss={:.5f}\"\\\n",
    "          .format(rec_loss_o, L1attr_loss_o, rec_loss, L1attr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wt.h1.data.squeeze().detach().cpu())\n",
    "plt.plot(wt_o.h1.data.squeeze().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wt.h0.data.squeeze().detach().cpu())\n",
    "plt.plot(wt_o.h0.data.squeeze().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
