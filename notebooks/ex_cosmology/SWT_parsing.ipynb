{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "\n",
    "sys.path.append('../../src')\n",
    "sys.path.append('../../src/vae/models')\n",
    "sys.path.append('../../src/dsets/cosmology')\n",
    "from dset import get_dataloader\n",
    "from losses import _reconstruction_loss\n",
    "from viz import viz_im_r, cshow, viz_filters\n",
    "from sim_cosmology import p, load_dataloader_and_pretrained_model\n",
    "from captum.attr import *\n",
    "\n",
    "# trim modules\n",
    "sys.path.append('../../lib/trim')\n",
    "from trim import TrimModel\n",
    "\n",
    "# wt modules\n",
    "from wavelet_transform import Wavelet_Transform, DTCWT_Mask, tuple_Attributer, create_images_high_attrs, compute_tuple_dim\n",
    "from wavelet_transform import Wavelet_Transform_from_Scratch\n",
    "import pywt\n",
    "from pytorch_wavelets import DTCWTForward, DTCWTInverse, DWTForward, DWTInverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloader and model\n",
    "train_loader, model = load_dataloader_and_pretrained_model(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims, param = iter(train_loader).next()\n",
    "im = ims[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfm = DTCWTForward(J=3, biort='near_sym_b', qshift='qshift_b')\n",
    "ifm = DTCWTInverse(biort='near_sym_b', qshift='qshift_b')\n",
    "Yl, Yh = xfm(im)\n",
    "Y = ifm((Yl, Yh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## undecimated transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pywt\n",
    "import pytorch_wavelets.dwt.lowlevel as lowlevel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWTForward(nn.Module):\n",
    "    \"\"\" Performs a 2d Stationary wavelet transform (or undecimated wavelet\n",
    "    transform) of an image\n",
    "\n",
    "    Args:\n",
    "        J (int): Number of levels of decomposition\n",
    "        wave (str or pywt.Wavelet): Which wavelet to use. Can be a string to\n",
    "            pass to pywt.Wavelet constructor, can also be a pywt.Wavelet class,\n",
    "            or can be a two tuple of array-like objects for the analysis low and\n",
    "            high pass filters.\n",
    "        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. The\n",
    "            padding scheme. PyWavelets uses only periodization so we use this\n",
    "            as our default scheme.\n",
    "        \"\"\"\n",
    "    def __init__(self, J=1, wave='db1', mode='periodization'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            h0_col, h1_col = wave.dec_lo, wave.dec_hi\n",
    "            h0_row, h1_row = h0_col, h1_col\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                h0_col, h1_col = wave[0], wave[1]\n",
    "                h0_row, h1_row = h0_col, h1_col\n",
    "            elif len(wave) == 4:\n",
    "                h0_col, h1_col = wave[0], wave[1]\n",
    "                h0_row, h1_row = wave[2], wave[3]\n",
    "\n",
    "        # Prepare the filters\n",
    "        filts = lowlevel.prep_filt_afb2d(h0_col, h1_col, h0_row, h1_row)\n",
    "        self.register_buffer('h0_col', filts[0])\n",
    "        self.register_buffer('h1_col', filts[1])\n",
    "        self.register_buffer('h0_row', filts[2])\n",
    "        self.register_buffer('h1_row', filts[3])\n",
    "\n",
    "        self.J = J\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass of the SWT.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n",
    "\n",
    "        Returns:\n",
    "            List of coefficients for each scale. Each coefficient has\n",
    "            shape :math:`(N, C_{in}, 4, H_{in}, W_{in})` where the extra\n",
    "            dimension stores the 4 subbands for each scale. The ordering in\n",
    "            these 4 coefficients is: (A, H, V, D) or (ll, lh, hl, hh).\n",
    "        \"\"\"\n",
    "        ll = x\n",
    "        coeffs = []\n",
    "        # Do a multilevel transform\n",
    "        filts = (self.h0_col, self.h1_col, self.h0_row, self.h1_row)\n",
    "        for j in range(self.J):\n",
    "            # Do 1 level of the transform\n",
    "            y = lowlevel.afb2d_atrous(ll, filts, self.mode, 2**j)\n",
    "            coeffs.append(y)\n",
    "            ll = y[:,:,0]\n",
    "\n",
    "        return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWTInverse(nn.Module):\n",
    "    \"\"\" Performs a 2d DWT Inverse reconstruction of an image\n",
    "\n",
    "    Args:\n",
    "        wave (str or pywt.Wavelet): Which wavelet to use\n",
    "        C: deprecated, will be removed in future\n",
    "    \"\"\"\n",
    "    def __init__(self, wave='db1', mode='zero', separable=True):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            g0_col, g1_col = wave.rec_lo, wave.rec_hi\n",
    "            g0_row, g1_row = g0_col, g1_col\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                g0_col, g1_col = wave[0], wave[1]\n",
    "                g0_row, g1_row = g0_col, g1_col\n",
    "            elif len(wave) == 4:\n",
    "                g0_col, g1_col = wave[0], wave[1]\n",
    "                g0_row, g1_row = wave[2], wave[3]\n",
    "        # Prepare the filters\n",
    "        if separable:\n",
    "            filts = lowlevel.prep_filt_sfb2d(g0_col, g1_col, g0_row, g1_row)\n",
    "            self.register_buffer('g0_col', filts[0])\n",
    "            self.register_buffer('g1_col', filts[1])\n",
    "            self.register_buffer('g0_row', filts[2])\n",
    "            self.register_buffer('g1_row', filts[3])\n",
    "        else:\n",
    "            filts = lowlevel.prep_filt_sfb2d_nonsep(\n",
    "                g0_col, g1_col, g0_row, g1_row)\n",
    "            self.register_buffer('h', filts)\n",
    "        self.mode = mode\n",
    "        self.separable = separable\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            coeffs (yl, yh): tuple of lowpass and bandpass coefficients, where:\n",
    "              yl is a lowpass tensor of shape :math:`(N, C_{in}, H_{in}',\n",
    "              W_{in}')` and yh is a list of bandpass tensors of shape\n",
    "              :math:`list(N, C_{in}, 3, H_{in}'', W_{in}'')`. I.e. should match\n",
    "              the format returned by DWTForward\n",
    "\n",
    "        Returns:\n",
    "            Reconstructed input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n",
    "\n",
    "        Note:\n",
    "            :math:`H_{in}', W_{in}', H_{in}'', W_{in}''` denote the correctly\n",
    "            downsampled shapes of the DWT pyramid.\n",
    "\n",
    "        Note:\n",
    "            Can have None for any of the highpass scales and will treat the\n",
    "            values as zeros (not in an efficient way though).\n",
    "        \"\"\"\n",
    "        yl, yh = coeffs\n",
    "        ll = yl\n",
    "\n",
    "        # Do a multilevel inverse transform\n",
    "        for h in yh[::-1]:\n",
    "            if h is None:\n",
    "                h = torch.zeros(ll.shape[0], ll.shape[1], 3, ll.shape[-2],\n",
    "                                ll.shape[-1], device=ll.device)\n",
    "\n",
    "            # 'Unpad' added dimensions\n",
    "            if ll.shape[-2] > h.shape[-2]:\n",
    "                ll = ll[...,:-1,:]\n",
    "            if ll.shape[-1] > h.shape[-1]:\n",
    "                ll = ll[...,:-1]\n",
    "\n",
    "            # Do the synthesis filter banks\n",
    "            if self.separable:\n",
    "                lh, hl, hh = torch.unbind(h, dim=2)\n",
    "                filts = (self.g0_col, self.g1_col, self.g0_row, self.g1_row)\n",
    "                ll = lowlevel.sfb2d(ll, lh, hl, hh, filts, mode=self.mode)\n",
    "            else:\n",
    "                c = torch.cat((ll[:,:,None], h), dim=2)\n",
    "                ll = lowlevel.sfb2d_nonsep(c, self.h, mode=self.mode)\n",
    "        return ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims, param = iter(train_loader).next()\n",
    "im = ims[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfm = SWTForward(J=2, wave='db3', mode='zero')\n",
    "ifm = SWTInverse(wave='db3', mode='zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 8 1 1 6, but got 3-dimensional input of size [1, 4, 266] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-493f77f35fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSWTForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'db3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zero'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-117ebbfbb468>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Do 1 level of the transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowlevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafb2d_atrous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mcoeffs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_wavelets/dwt/lowlevel.py\u001b[0m in \u001b[0;36mafb2d_atrous\u001b[0;34m(x, filts, mode, dilation)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown form for input filts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0mlohi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafb1d_atrous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafb1d_atrous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlohi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_wavelets/dwt/lowlevel.py\u001b[0m in \u001b[0;36mafb1d_atrous\u001b[0;34m(x, h0, h1, mode, dim, dilation)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmypad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mlohi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlohi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 8 1 1 6, but got 3-dimensional input of size [1, 4, 266] instead"
     ]
    }
   ],
   "source": [
    "print(im.shape)\n",
    "xfm = SWTForward(J=2, wave='db3', mode='zero')\n",
    "xfm(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfm = DTCWTForward(J=3, biort='near_sym_b', qshift='qshift_b')\n",
    "ifm = DTCWTInverse(biort='near_sym_b', qshift='qshift_b')\n",
    "Yl, Yh = xfm(im)\n",
    "Y = ifm((Yl, Yh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
