{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 4)\n"
     ]
    }
   ],
   "source": [
    "data_dir_path = './data'\n",
    "\n",
    "# Import `fake_or_real_news.csv`\n",
    "df = pd.read_csv(data_dir_path + \"/fake_or_real_news.csv\")\n",
    "\n",
    "# Inspect shape of `df`\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        title  \\\n",
      "Unnamed: 0                                                      \n",
      "8476                             You Can Smell Hillary’s Fear   \n",
      "10294       Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "3608              Kerry to go to Paris in gesture of sympathy   \n",
      "10142       Bernie supporters on Twitter erupt in anger ag...   \n",
      "875          The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                         text label  \n",
      "Unnamed: 0                                                           \n",
      "8476        Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "10294       Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "3608        U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "10142       — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "875         It's primary day in New York and front-runners...  REAL  \n"
     ]
    }
   ],
   "source": [
    "# Set index\n",
    "df = df.set_index(\"Unnamed: 0\")\n",
    "\n",
    "# Print first lines of `df`\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `y`\n",
    "y = df.label\n",
    "\n",
    "# Drop the `label` column\n",
    "df.drop(\"label\", axis=1)\n",
    "\n",
    "# Make training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer`\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training and test data\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the `tfidf_vectorizer`\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Fit and transform the training and test data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n",
      "['حلب', 'عربي', 'عن', 'لم', 'ما', 'محاولات', 'من', 'هذا', 'والمرضى', 'ยงade']\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names of `count_vectorizer`\n",
    "print(count_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Get the feature names of `tfidf_vectorizer`\n",
    "print(tfidf_vectorizer.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "1   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "2   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "3   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "4   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "\n",
      "   حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
      "0    0     0   0   0   0        0   0    0        0      0  \n",
      "1    0     0   0   0   0        0   0    0        0      0  \n",
      "2    0     0   0   0   0        0   0    0        0      0  \n",
      "3    0     0   0   0   0        0   0    0        0      0  \n",
      "4    0     0   0   0   0        0   0    0        0      0  \n",
      "\n",
      "[5 rows x 56922 columns]\n",
      "    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "\n",
      "   حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  ยงade  \n",
      "0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "\n",
      "[5 rows x 56922 columns]\n",
      "False\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "print(count_df.head())\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "print(tfidf_df.head())\n",
    "\n",
    "print(count_df.equals(tfidf_df))\n",
    "\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
