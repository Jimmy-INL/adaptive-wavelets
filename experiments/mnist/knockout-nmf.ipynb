{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "from transforms_torch import bandpass_filter\n",
    "# plt.style.use('dark_background')\n",
    "sys.path.append('../../dsets/mnist')\n",
    "import dset\n",
    "from model import Net, Net2c\n",
    "from util import *\n",
    "from numpy.fft import *\n",
    "from torch import nn\n",
    "from style import *\n",
    "from captum.attr import (\n",
    "    GradientShap,\n",
    "    DeepLift,\n",
    "    DeepLiftShap,\n",
    "    IntegratedGradients,\n",
    "    LayerConductance,\n",
    "    NeuronConductance,\n",
    "    NoiseTunnel,\n",
    ")\n",
    "import pickle as pkl\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import NMF\n",
    "import transform_wrappers\n",
    "import visualize as viz\n",
    "from model import Net, Net2c\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acd_wooseok.acd.scores import cd\n",
    "from acd_wooseok.acd.util import tiling_2d\n",
    "from acd_wooseok.acd.scores import score_funcs\n",
    "from torchvision import datasets, transforms\n",
    "# import modules\n",
    "from funcs import *\n",
    "from matfac import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load args\n",
    "args = dset.get_args()\n",
    "args.batch_size = int(args.batch_size/2) # half the batchsize\n",
    "args.epochs = 50\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# load mnist dataloader\n",
    "train_loader, test_loader = dset.load_data_with_indices(args.batch_size, args.test_batch_size, device)\n",
    "\n",
    "# dataset\n",
    "X = train_loader.dataset.data.numpy().astype(np.float32)\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "X /= 255\n",
    "Y = train_loader.dataset.targets.numpy()\n",
    "\n",
    "X_test = test_loader.dataset.data.numpy().astype(np.float32)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "X_test /= 255\n",
    "Y_test = test_loader.dataset.targets.numpy()\n",
    "\n",
    "# load NMF object\n",
    "# run NMF\n",
    "# nmf = NMF(n_components=30, max_iter=1000)\n",
    "# nmf.fit(X)\n",
    "# pkl.dump(nmf, open('./results/nmf_30.pkl', 'wb'))\n",
    "nmf = pkl.load(open('./results/nmf_30.pkl', 'rb'))\n",
    "D = nmf.components_\n",
    "# nmf transform\n",
    "W = nmf.transform(X) \n",
    "W_test = nmf.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knockout first dictionary and redefine train and test dataset\n",
    "indx = np.argwhere(nmf.transform(X)[:,0] > 0).flatten()\n",
    "indx_t = np.argwhere(nmf.transform(X_test)[:,0] > 0).flatten()\n",
    "\n",
    "# subset dataloader\n",
    "train_loader, test_loader = dset.load_data_with_indices(args.batch_size, \n",
    "                                                        args.test_batch_size, \n",
    "                                                        device, \n",
    "                                                        subset_index=[indx, indx_t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmf_transform(W: np.array, data_indx, list_dict_indx=[0]):\n",
    "    im_parts = W[data_indx][:,list_dict_indx] @ D[list_dict_indx] / 0.3081\n",
    "    im_parts = torch.Tensor(im_parts).reshape(batch_size, 1, 28, 28)\n",
    "    return im_parts\n",
    "\n",
    "def nmf_knockout_augment(im: torch.Tensor, W: np.array, data_indx, list_dict_indx=[0]):\n",
    "    batch_size = im.size()[0]\n",
    "    im_copy = deepcopy(im)\n",
    "    im_parts = nmf_transform(W, data_indx, list_dict_indx)\n",
    "    im_copy = torch.cat((im_copy,im-im_parts), dim=0)\n",
    "    return im_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    \n",
    "# create model\n",
    "model = Net2c()\n",
    "if args.cuda:\n",
    "    model.cuda()  \n",
    "    \n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum) \n",
    "\n",
    "# train\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    model.train()\n",
    "    for batch_indx, (data, target, data_indx) in enumerate(train_loader):\n",
    "        batch_size = len(data)\n",
    "        data = nmf_knockout_augment(data, W, data_indx, list_dict_indx=[0])\n",
    "        target = torch.zeros(2*batch_size, dtype=target.dtype)\n",
    "        target[batch_size:] = 1\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()     \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_indx % args.log_interval == 0:\n",
    "            print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_indx * len(data), 2*len(train_loader.dataset),\n",
    "                       100. * batch_indx / len(train_loader), loss.data.item()), end='')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval mode\n",
    "model.eval()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "# test\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "for batch_indx, (data, target, data_indx) in tqdm(enumerate(test_loader)):\n",
    "    batch_size = len(data)\n",
    "    data = nmf_knockout_augment(data, W_test, data_indx, list_dict_indx=[0])\n",
    "    target = torch.zeros(2*batch_size, dtype=target.dtype)\n",
    "    target[batch_size:] = 1\n",
    "    if args.cuda:\n",
    "        data, target = data.cuda(), target.cuda()       \n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target, reduction='sum').data.item()  # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "test_loss /= 2*len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, 2*len(test_loader.dataset),\n",
    "    100. * correct / (2*len(test_loader.dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CD score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = len(indx_t)\n",
    "\n",
    "# true band centers model is trained with\n",
    "scores_o = torch.zeros(test_num, nmf.n_components) # cd score for class 0 (original img)\n",
    "scores_f = torch.zeros(test_num, nmf.n_components) # cd score for class 1 (transformed img)\n",
    "\n",
    "n = 0\n",
    "for batch_indx, (data, target, data_indx) in enumerate(test_loader):\n",
    "    batch_size = len(data)\n",
    "    data_f = data - nmf_transform(W_test, data_indx, list_dict_indx=[0])\n",
    "    # eval mode\n",
    "    model.eval()\n",
    "    if args.cuda:\n",
    "        model.cuda()    \n",
    "    for comp_indx in range(nmf.n_components):\n",
    "        im_parts = nmf_transform(W_test, data_indx, list_dict_indx=[comp_indx])\n",
    "        score_o = cd.cd(data, model, mask=None, model_type='mnist', device='cuda',\n",
    "                                   transform=None, relevant=im_parts)[0].data.cpu()\n",
    "        score_f = cd.cd(data-im_parts, model, mask=None, model_type='mnist', device='cuda',\n",
    "                                   transform=None, relevant=im_parts)[0].data.cpu()\n",
    "        \n",
    "        scores_o[n:n+batch_size,comp_indx] = score_o[:,0]\n",
    "        scores_f[n:n+batch_size,comp_indx] = score_o[:,1]\n",
    "        print('\\r batch index: {} [component index: {}]'.format(batch_indx, comp_indx), end='')     \n",
    "    n += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_x = np.arange(nmf.n_components)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13,5))\n",
    "ax[0].plot(list_of_x, scores_o.mean(axis=0), alpha=0.5, color='blue', label='class(original)', linewidth=4.0)\n",
    "ax[0].fill_between(list_of_x, scores_o.mean(axis=0)-scores_o.std(axis=0), \n",
    "                    scores_o.mean(axis=0)+scores_o.std(axis=0), color='#888888', alpha=0.4)\n",
    "ax[0].axvline(x=0, linestyle='--', color='green', label='true band center', linewidth=2.0)\n",
    "ax[0].set_xlabel('dictionary index')\n",
    "ax[0].set_ylabel('cd score')\n",
    "ax[0].set_title('Averaged CD score')\n",
    "# ax[0].set_title('Test accuracy: {}/{} ({:.0f}%)'.format(accuracies[band_idx], 2*len(test_loader.dataset),\n",
    "#         100. * accuracies[band_idx] / (2*len(test_loader.dataset))))\n",
    "# ax[0].legend()\n",
    "\n",
    "ax[1].hist(np.argmax(scores_o,axis=1), bins=30, alpha=0.4)\n",
    "ax[1].axvline(x=0, linestyle='--', color='green', label='true band center', linewidth=2.0)\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('dictionary index')\n",
    "ax[1].set_ylabel('frequency')\n",
    "ax[1].set_title('Maximum dictionary index for each data point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
