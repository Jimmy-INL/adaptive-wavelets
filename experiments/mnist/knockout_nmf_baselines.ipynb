{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "from transforms_torch import bandpass_filter\n",
    "# plt.style.use('dark_background')\n",
    "sys.path.append('../../dsets/mnist')\n",
    "import dset\n",
    "from model import Net, Net2c\n",
    "from util import *\n",
    "from numpy.fft import *\n",
    "from torch import nn\n",
    "from style import *\n",
    "from captum.attr import (\n",
    "    InputXGradient,\n",
    "    Saliency,\n",
    "    GradientShap,\n",
    "    DeepLift,\n",
    "    DeepLiftShap,\n",
    "    IntegratedGradients,\n",
    "    LayerConductance,\n",
    "    NeuronConductance,\n",
    "    NoiseTunnel,\n",
    ")\n",
    "import pickle as pkl\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import NMF\n",
    "import transform_wrappers\n",
    "import visualize as viz\n",
    "from model import Net, Net2c\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acd_wooseok.acd.scores import cd\n",
    "from acd_wooseok.acd.util import tiling_2d\n",
    "from acd_wooseok.acd.scores import score_funcs\n",
    "from torchvision import datasets, transforms\n",
    "# import modules\n",
    "from funcs import *\n",
    "from matfac import *\n",
    "sys.path.append('../../..')\n",
    "from hierarchical_dnn_interpretations.acd.scores import cd as acd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load args\n",
    "args = dset.get_args()\n",
    "args.batch_size = int(args.batch_size/2) # half the batchsize\n",
    "args.epochs = 50\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# load mnist dataloader\n",
    "train_loader, test_loader = dset.load_data_with_indices(args.batch_size, args.test_batch_size, device)\n",
    "\n",
    "# dataset\n",
    "X = train_loader.dataset.data.numpy().astype(np.float32)\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "X /= 255\n",
    "Y = train_loader.dataset.targets.numpy()\n",
    "\n",
    "X_test = test_loader.dataset.data.numpy().astype(np.float32)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "X_test /= 255\n",
    "Y_test = test_loader.dataset.targets.numpy()\n",
    "\n",
    "# load NMF object\n",
    "# run NMF\n",
    "# nmf = NMF(n_components=30, max_iter=1000)\n",
    "# nmf.fit(X)\n",
    "# pkl.dump(nmf, open('./results/nmf_30.pkl', 'wb'))\n",
    "nmf = pkl.load(open('./results/nmf_30.pkl', 'rb'))\n",
    "D = nmf.components_\n",
    "# nmf transform\n",
    "W = nmf.transform(X) \n",
    "W_test = nmf.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indx = 1\n",
    "model = Net2c().to(device)\n",
    "model.load_state_dict(torch.load('models/nmf/net2c_{}.pth'.format(dict_indx), map_location=device))\n",
    "model = model.eval()\n",
    "\n",
    "# knockout first dictionary and redefine train and test dataset\n",
    "indx = np.argwhere(W[:,dict_indx] > 0).flatten()\n",
    "indx_t = np.argwhere(W_test[:,dict_indx] > 0).flatten()\n",
    "\n",
    "# subset dataloader\n",
    "train_loader, test_loader = dset.load_data_with_indices(args.batch_size,\n",
    "                                                        args.test_batch_size,\n",
    "                                                        device,\n",
    "                                                        subset_index=[indx, indx_t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score NMF basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network with transform augmented\n",
    "transform = transform_wrappers.lay_from_w(D)\n",
    "norm = transform_wrappers.NormLayer(mu=0.1307, std=0.3081)\n",
    "reshape = transform_wrappers.ReshapeLayer(shape=(1, 28, 28))\n",
    "net = transform_wrappers.Net_with_transform(model, \n",
    "                                            transform=transform, \n",
    "                                            norm=norm, \n",
    "                                            reshape=reshape,\n",
    "                                            use_logits=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert nmf weight to tensor\n",
    "W_test_t = torch.Tensor(W_test)\n",
    "\n",
    "# interp modules\n",
    "gradient_shap = GradientShap(net)\n",
    "ig = IntegratedGradients(net)\n",
    "saliency = Saliency(net)\n",
    "input_x_gradient = InputXGradient(net)\n",
    "\n",
    "# store results\n",
    "results = {\n",
    "    'gradient_shap': [],\n",
    "    'ig': [],\n",
    "    'saliency': [],\n",
    "    'input_x_gradient': []\n",
    "}\n",
    "for batch_indx, (data, target, data_indx) in enumerate(test_loader):\n",
    "    # loop over nmf basis\n",
    "    x_t = W_test_t[data_indx].to(device).requires_grad_(True)\n",
    "    # comp gradient\n",
    "    baselines = torch.zeros_like(x_t)\n",
    "    results['gradient_shap'].append(gradient_shap.attribute(x_t, baselines=baselines, target=0).cpu().detach().numpy())\n",
    "    results['ig'].append(ig.attribute(x_t, target=0).cpu().detach().numpy())\n",
    "    results['saliency'].append(saliency.attribute(x_t, target=0, abs=False).cpu().detach().numpy())\n",
    "    results['input_x_gradient'].append(input_x_gradient.attribute(x_t, target=0).cpu().detach().numpy())\n",
    "\n",
    "    print('\\r batch index: {}'.format(batch_indx), end='')  \n",
    "\n",
    "results['gradient_shap'] = np.vstack(results['gradient_shap'])\n",
    "results['ig'] = np.vstack(results['ig'])\n",
    "results['saliency'] = np.vstack(results['saliency'])\n",
    "results['input_x_gradient'] = np.vstack(results['input_x_gradient'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_x = np.arange(nmf.n_components)\n",
    "interp_modules = ['gradient_shap', 'ig', 'saliency', 'input_x_gradient']\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(12, 6))\n",
    "for c in range(4):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.plot(list_of_x, results[interp_modules[i]].mean(axis=0), alpha=0.5, color='blue', linewidth=4.0)\n",
    "    plt.fill_between(list_of_x, results[interp_modules[i]].mean(axis=0)-results[interp_modules[i]].std(axis=0), \n",
    "                results[interp_modules[i]].mean(axis=0)+results[interp_modules[i]].std(axis=0), color='#888888', alpha=0.4)\n",
    "    plt.axvline(x=dict_indx, linestyle='--', color='green', label='true basis', linewidth=2.0)\n",
    "    plt.legend()\n",
    "    plt.xlabel('basis index')\n",
    "    plt.ylabel('interp score')\n",
    "    plt.title(interp_modules[i])\n",
    "    \n",
    "    plt.subplot(2, 4, i + 5)\n",
    "    plt.hist(np.argmax(results[interp_modules[i]],axis=1), bins=list_of_x-0.5, alpha=0.4)\n",
    "    plt.axvline(x=dict_indx, linestyle='--', color='green', label='true basis', linewidth=2.0)\n",
    "    plt.legend()\n",
    "    plt.xlabel('basis index')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.title('Max basis index')    \n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad*basis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf transform layers\n",
    "nmf_transformer = transform_wrappers.TransformLayers(D).to(device)\n",
    "\n",
    "# # convert nmf weight to tensor\n",
    "W_test_t = torch.Tensor(W_test).to(device)\n",
    "sweep_dim = 1\n",
    "tiles = torch.Tensor(tiling_2d.gen_tiles(W_test[0:1], fill=0, method='cd', sweep_dim=sweep_dim)).to(device)\n",
    "\n",
    "# interp modules\n",
    "saliency = Saliency(model)\n",
    "ig = IntegratedGradients(model)\n",
    "\n",
    "# store results\n",
    "results['dot_product'] = []\n",
    "\n",
    "for batch_indx, (data, target, data_indx) in enumerate(test_loader):\n",
    "    # set requires_grad \n",
    "    data = data.to(device).requires_grad_(True)\n",
    "    # comp gradient\n",
    "    attribution = saliency.attribute(data, target=0, abs=False)\n",
    "    # loop over nmf basis\n",
    "    scores = []\n",
    "    for basis_indx in range(nmf.n_components):\n",
    "        im_parts = nmf_transformer(W_test_t[data_indx]*tiles[basis_indx])\n",
    "        scores.append(torch.sum(attribution * im_parts, axis=(1,2,3)).cpu().detach().numpy())\n",
    "        \n",
    "        print('\\r batch index: {} [component index: {}]'.format(batch_indx, basis_indx), end='')  \n",
    "        \n",
    "    scores = np.vstack(scores).T\n",
    "    results['dot_product'].append(scores)\n",
    "results['dot_product'] = np.vstack(results['dot_product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_x = np.arange(nmf.n_components)\n",
    "interp_modules += ['dot_product']\n",
    "\n",
    "i = 4\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(list_of_x, results[interp_modules[i]].mean(axis=0), alpha=0.5, color='blue', linewidth=4.0)\n",
    "plt.fill_between(list_of_x, results[interp_modules[i]].mean(axis=0)-results[interp_modules[i]].std(axis=0), \n",
    "            results[interp_modules[i]].mean(axis=0)+results[interp_modules[i]].std(axis=0), color='#888888', alpha=0.4)\n",
    "plt.axvline(x=dict_indx, linestyle='--', color='green', label='true basis', linewidth=2.0)\n",
    "plt.legend()\n",
    "plt.xlabel('basis index')\n",
    "plt.ylabel('interp score')\n",
    "plt.title(interp_modules[i])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.argmax(results[interp_modules[i]],axis=1), bins=list_of_x-0.5, alpha=0.4)\n",
    "plt.axvline(x=dict_indx, linestyle='--', color='green', label='true basis', linewidth=2.0)\n",
    "plt.legend()\n",
    "plt.xlabel('basis index')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Max basis index')    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
