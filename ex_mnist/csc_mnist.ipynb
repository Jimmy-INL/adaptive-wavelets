{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "sys.path.append('..')\n",
    "sys.path.append('../trim')\n",
    "sys.path.append('../trim/transforms')\n",
    "from transforms_torch import bandpass_filter\n",
    "# plt.style.use('dark_background')\n",
    "sys.path.append('../../dsets/mnist')\n",
    "import dset_mnist as dset\n",
    "from model_mnist import Net, Net2c\n",
    "from util import *\n",
    "from numpy.fft import *\n",
    "from torch import nn\n",
    "from style import *\n",
    "from captum.attr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from acd_wooseok.acd.scores import cd\n",
    "from funcs import *\n",
    "from matfac import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "img_size = 28\n",
    "class_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load args\n",
    "args = dset.get_args()\n",
    "args.epochs = 20\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# load the model\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('../../dsets/mnist/mnist.model', map_location=device))\n",
    "model = model.eval()\n",
    "\n",
    "# data_loader\n",
    "train_loader, test_loader = dset.load_data(args.batch_size,\n",
    "                                           args.test_batch_size,\n",
    "                                           device,\n",
    "                                           return_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv sparse coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper-params and variables\n",
    "n_components = 32\n",
    "kernel_size = 7\n",
    "n_dim = kernel_size + (img_size-1)\n",
    "\n",
    "csc = Conv_SpCoding(kernel_size, n_dim, n_components).to(device)\n",
    "# load checkpoint\n",
    "# csc.load_state_dict(torch.load('./model/csc_maxCD_0.pth'))\n",
    "\n",
    "# reg-parameter\n",
    "lamb = 1.0e-3\n",
    "\n",
    "# losses\n",
    "n_inner_c = 10\n",
    "n_inner_w = 100\n",
    "losses = [1000]\n",
    "\n",
    "# set optimizer\n",
    "lr_c = 0.1\n",
    "lr_w = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [3000/60000 (0%)]\tError: 0.319829\tLoss: [166.391369, 166.344758, 165.837495]\tNNZ: 29.609126%"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_indx, (data, _, _) in enumerate(test_loader):\n",
    "        X = data.to(device)\n",
    "        n_batch = len(X)\n",
    "        # initialize act maps\n",
    "        csc.init_maps(n_batch)\n",
    "        csc.to(device)\n",
    "        optimizer = csc_optimizer(csc, lr_c, lr_w, lamb)\n",
    "        \n",
    "        # update weight\n",
    "        unfreeze(csc, param='map')\n",
    "        # inner loop\n",
    "        for i in range(n_inner_w):\n",
    "            optimizer.zero_grad() # clear the old gradients\n",
    "            # comp loss\n",
    "            X_ = csc()\n",
    "            loss = torch.norm(X-X_)**2/(2*n_batch)    \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            # update step\n",
    "            optimizer.step(1)    \n",
    "\n",
    "        reg_loss = L1Reg_loss(csc, X, lamb)\n",
    "        losses.append(reg_loss)      \n",
    "\n",
    "        # update dict\n",
    "        unfreeze(csc, param='dict', obj_type='csc')\n",
    "        # inner loop\n",
    "        for i in range(n_inner_c):\n",
    "            optimizer.zero_grad() # clear the old gradients\n",
    "            # comp loss\n",
    "            X_ = csc()\n",
    "            loss = torch.norm(X-X_)**2/(2*n_batch)\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            # update step\n",
    "            optimizer.step(0)    \n",
    "\n",
    "        reg_loss = L1Reg_loss(csc, X, lamb)\n",
    "        losses.append(reg_loss)             \n",
    "\n",
    "        # recon-error, nnz\n",
    "        err = torch.norm(X-X_).data.item() / torch.norm(X).data.item() \n",
    "        nnz = 0\n",
    "        for feature_map in csc.maps:\n",
    "            nnz += np.count_nonzero(feature_map.data.cpu().numpy())\n",
    "        nnz_W = nnz/(n_dim*n_dim*n_components*n_batch)\n",
    "\n",
    "        print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)]\\tError: {:.6f}\\tLoss: [{:.6f}, {:.6f}, {:.6f}]\\tNNZ: {:.6f}%'.format(\n",
    "            epoch, batch_indx * len(data), len(train_loader.dataset), err, \n",
    "            100. * batch_indx / len(train_loader), losses[-3], losses[-2], losses[-1], 100. * nnz_W), end='')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rescale\n",
    "\n",
    "n_row = 4\n",
    "n_col = 8\n",
    "Nimages = len(csc.convs)\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "# plot filters\n",
    "plt.subplot(1, 2, 1)\n",
    "p = kernel_size + 2\n",
    "mosaic = np.zeros((p*n_row,p*n_col))\n",
    "indx = 0\n",
    "for i in range(n_row):\n",
    "    for j in range(n_col):\n",
    "        im = csc.convs[indx].weight.data.cpu().squeeze().numpy()\n",
    "        im = (im-np.min(im))\n",
    "        im = im/np.max(im)\n",
    "        mosaic[i*p:(i+1)*p,j*p:(j+1)*p] = np.pad(im,(1,1),mode='constant')\n",
    "        indx += 1\n",
    "\n",
    "plt.imshow(rescale(mosaic,4,mode='constant'), cmap='gray')\n",
    "plt.axis('off')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 50\n",
    "# for epoch in range(num_epochs):\n",
    "#     # initialize act maps\n",
    "#     csc.init_maps(n_batch)\n",
    "#     csc.to(device)\n",
    "#     optimizer = csc_optimizer(csc, lr_c, lr_w, lamb)\n",
    "    \n",
    "#     # update weight\n",
    "#     unfreeze(csc, param='map')\n",
    "#     # inner loop\n",
    "#     for i in range(n_inner_w):\n",
    "#         optimizer.zero_grad() # clear the old gradients\n",
    "#         # comp loss\n",
    "#         X_ = csc()\n",
    "#         loss = torch.norm(X-X_)**2/(2*n_batch)    \n",
    "#         # backward\n",
    "#         loss.backward()\n",
    "#         # update step\n",
    "#         optimizer.step(1)    \n",
    "\n",
    "#     reg_loss = L1Reg_loss(csc, X, lamb)\n",
    "#     losses.append(reg_loss)      \n",
    "\n",
    "#     # update dict\n",
    "#     unfreeze(csc, param='dict', obj_type='csc')\n",
    "#     # inner loop\n",
    "#     for i in range(n_inner_c):\n",
    "#         optimizer.zero_grad() # clear the old gradients\n",
    "#         # comp loss\n",
    "#         X_ = csc()\n",
    "#         loss = torch.norm(X-X_)**2/(2*n_batch)\n",
    "#         # backward\n",
    "#         loss.backward()\n",
    "#         # update step\n",
    "#         optimizer.step(0)    \n",
    "\n",
    "#     reg_loss = L1Reg_loss(csc, X, lamb)\n",
    "#     losses.append(reg_loss)             \n",
    "\n",
    "#     if epoch % 1 == 0:\n",
    "#         # recon-error, nnz\n",
    "#         err = torch.norm(X-X_).data.item() / torch.norm(X).data.item() \n",
    "#         nnz = 0\n",
    "#         for feature_map in csc.maps:\n",
    "#             nnz += np.count_nonzero(feature_map.data.cpu().numpy())\n",
    "#         nnz_W = nnz/(n_dim*n_dim*n_components*n_batch)\n",
    "\n",
    "#         print('\\rTrain Epoch: {} [({:.0f}%)]\\tError: {:.6f}\\tLoss: [{:.6f}, {:.6f}, {:.6f}]\\tNNZ: {:.6f}%'.format(\n",
    "#             epoch, 100. * epoch / num_epochs, err, losses[-3], losses[-2], losses[-1], 100. * nnz_W), end='')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
