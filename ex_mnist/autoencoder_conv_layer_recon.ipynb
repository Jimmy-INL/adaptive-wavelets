{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "from model_mnist import LeNet5, LinAutoencoder, ConvAutoencoder\n",
    "from visualize import *\n",
    "import autoencoder \n",
    "import dset_mnist as dset\n",
    "import foolbox\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 9907/10000 (99.07%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set args\n",
    "args = dset.get_args()\n",
    "args.cuda = True\n",
    "\n",
    "# load mnist data\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.test_batch_size, device)\n",
    "\n",
    "# load model\n",
    "m = LeNet5().eval()\n",
    "m.load_state_dict(torch.load('weights/lenet_epoch=12_test_acc=0.991.pth'))\n",
    "m = m.to(device)\n",
    "\n",
    "# test model\n",
    "dset.test(m, test_loader, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb_grid = np.geomspace(1e-6, 0.5, 20)\n",
    "Losses = []\n",
    "tLosses = []\n",
    "\n",
    "# number of epochs to train the model\n",
    "num_epochs = 20\n",
    "\n",
    "for i,lamb in enumerate(lamb_grid):\n",
    "    print(i)\n",
    "    # initialize the NN\n",
    "    model = ConvAutoencoder().to(device)\n",
    "\n",
    "    # prepend model\n",
    "    m_t = TrimModel(m, model.i_transformer, use_residuals=True)\n",
    "\n",
    "    losses = []\n",
    "    tlosses = []\n",
    "    num_delay = 0\n",
    "    \n",
    "    best_loss = 1e+10\n",
    "\n",
    "    # actually do training\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model, train_loss = autoencoder.train(epoch, train_loader, model, m_t, lamb)\n",
    "        test_loss = autoencoder.test(test_loader, model, m_t, lamb)\n",
    "\n",
    "        # print avg training statistics \n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        test_loss = test_loss/len(test_loader.dataset)\n",
    "        print('\\nEpoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss))\n",
    "        losses.append(train_loss)\n",
    "        tlosses.append(test_loss)\n",
    "        if test_loss <= best_loss:\n",
    "            best_loss = test_loss\n",
    "            num_delay = 0\n",
    "        else:\n",
    "            num_delay += 1\n",
    "\n",
    "#         if num_delay == 3:\n",
    "#             break\n",
    "            \n",
    "    torch.save(model.state_dict(), 'results/autoencoder_conv_layer_supervised/transform_' + str(np.around(lamb, 6)))              \n",
    "    Losses.append(losses)\n",
    "    tLosses.append(tlosses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model.load_state_dict(torch.load('results/autoencoder_conv_layer_supervised/transform_' + str(np.around(lamb, 6))))\n",
    "\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images[70:80]\n",
    "model = model.to('cpu')\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# output is resized into a batch of images\n",
    "output = output.view(10, 1, 32, 32)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().numpy()\n",
    "\n",
    "print(np.linalg.norm(output - images))\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "lamb = lamb_grid[-1]\n",
    "model.load_state_dict(torch.load('results/autoencoder_conv_layer_supervised/transform_' + str(np.around(lamb, 6))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz filters\n",
    "viz_tensors(m.convnet.c1.weight.squeeze(), n_row=2, n_col=3, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz filters\n",
    "viz_tensors(model.conv1.weight, n_row=4, n_col=4, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "inputs, labels = iter(test_loader).next()\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# get attributions\n",
    "model = model.to(device)\n",
    "m_t = TrimModel(m, model.i_transformer, use_residuals=True)\n",
    "\n",
    "s = model.transformer(inputs)\n",
    "attributer = InputXGradient(m_t)\n",
    "# attributer = IntegratedGradients(m_t)        \n",
    "attributions = attributer.attribute(s, target=labels, additional_forward_args=deepcopy(inputs))\n",
    "# standardization\n",
    "# mean = attributions.mean(dim=1, keepdim=True)\n",
    "# std = attributions.std(dim=1, keepdim=True)\n",
    "# attributions = (attributions - mean) / std   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz filters\n",
    "viz_tensors(attributions[0], n_row=4, n_col=4, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
