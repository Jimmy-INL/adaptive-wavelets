{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "from model_mnist import LeNet5\n",
    "from visualize import *\n",
    "import dset_mnist as dset\n",
    "import foolbox\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# disentangled vae\n",
    "sys.path.append('../disentangling-vae')\n",
    "from collections import defaultdict\n",
    "import vae_trim, vae_trim_viz\n",
    "from disvae.utils.modelIO import save_model, load_model, load_metadata\n",
    "from disvae.models.losses import get_loss_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 0\n",
    "args.attr_lamb = 10\n",
    "args.epochs = 50\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B) + \"_attr_\" + str(args.attr_lamb)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:42:24 INFO - main: Root directory for saving and loading experiments: results/btcvae_B_0_attr_10\n",
      "11:42:24 INFO - main: Train mnist with 60000 samples\n",
      "11:42:24 INFO - main: Num parameters in model: 469173\n",
      "11:42:26 INFO - __init__: Training Device: cuda\n",
      "11:43:51 INFO - __call__: Epoch: 1 Average loss per image: 224.77\n",
      "11:45:17 INFO - __call__: Epoch: 2 Average loss per image: 183.25\n",
      "11:46:43 INFO - __call__: Epoch: 3 Average loss per image: 178.54\n",
      "11:48:09 INFO - __call__: Epoch: 4 Average loss per image: 175.97\n",
      "11:49:34 INFO - __call__: Epoch: 5 Average loss per image: 174.12\n",
      "11:50:58 INFO - __call__: Epoch: 6 Average loss per image: 172.73\n",
      "11:52:23 INFO - __call__: Epoch: 7 Average loss per image: 171.61\n",
      "11:53:45 INFO - __call__: Epoch: 8 Average loss per image: 170.72\n",
      "11:55:12 INFO - __call__: Epoch: 9 Average loss per image: 169.96\n",
      "11:56:36 INFO - __call__: Epoch: 10 Average loss per image: 169.33\n",
      "11:58:01 INFO - __call__: Epoch: 11 Average loss per image: 168.79\n",
      "11:59:28 INFO - __call__: Epoch: 12 Average loss per image: 168.28\n",
      "12:00:52 INFO - __call__: Epoch: 13 Average loss per image: 167.89\n",
      "12:02:20 INFO - __call__: Epoch: 14 Average loss per image: 167.45\n",
      "12:03:44 INFO - __call__: Epoch: 15 Average loss per image: 167.11\n",
      "12:05:09 INFO - __call__: Epoch: 16 Average loss per image: 166.86\n",
      "12:06:32 INFO - __call__: Epoch: 17 Average loss per image: 166.52\n",
      "12:07:59 INFO - __call__: Epoch: 18 Average loss per image: 166.26\n",
      "12:09:23 INFO - __call__: Epoch: 19 Average loss per image: 166.06\n",
      "12:10:48 INFO - __call__: Epoch: 20 Average loss per image: 165.74\n",
      "12:12:11 INFO - __call__: Epoch: 21 Average loss per image: 165.58\n",
      "12:13:36 INFO - __call__: Epoch: 22 Average loss per image: 165.35\n",
      "12:15:00 INFO - __call__: Epoch: 23 Average loss per image: 165.15\n",
      "12:16:25 INFO - __call__: Epoch: 24 Average loss per image: 164.99\n",
      "12:17:51 INFO - __call__: Epoch: 25 Average loss per image: 164.80\n",
      "12:19:19 INFO - __call__: Epoch: 26 Average loss per image: 164.68\n",
      "12:20:43 INFO - __call__: Epoch: 27 Average loss per image: 164.50\n",
      "12:22:08 INFO - __call__: Epoch: 28 Average loss per image: 164.37\n",
      "12:23:31 INFO - __call__: Epoch: 29 Average loss per image: 164.24\n",
      "12:24:56 INFO - __call__: Epoch: 30 Average loss per image: 164.09\n",
      "12:26:20 INFO - __call__: Epoch: 31 Average loss per image: 164.00\n",
      "12:27:43 INFO - __call__: Epoch: 32 Average loss per image: 163.86\n",
      "12:29:09 INFO - __call__: Epoch: 33 Average loss per image: 163.75\n",
      "12:30:32 INFO - __call__: Epoch: 34 Average loss per image: 163.64\n",
      "12:31:59 INFO - __call__: Epoch: 35 Average loss per image: 163.52\n",
      "12:33:22 INFO - __call__: Epoch: 36 Average loss per image: 163.44\n",
      "12:34:47 INFO - __call__: Epoch: 37 Average loss per image: 163.28\n",
      "12:36:13 INFO - __call__: Epoch: 38 Average loss per image: 163.19\n",
      "12:37:37 INFO - __call__: Epoch: 39 Average loss per image: 163.12\n",
      "12:39:01 INFO - __call__: Epoch: 40 Average loss per image: 163.07\n",
      "12:40:27 INFO - __call__: Epoch: 41 Average loss per image: 162.96\n",
      "12:41:50 INFO - __call__: Epoch: 42 Average loss per image: 162.90\n",
      "12:43:16 INFO - __call__: Epoch: 43 Average loss per image: 162.79\n",
      "12:44:39 INFO - __call__: Epoch: 44 Average loss per image: 162.73\n",
      "12:46:02 INFO - __call__: Epoch: 45 Average loss per image: 162.65\n",
      "12:47:24 INFO - __call__: Epoch: 46 Average loss per image: 162.58\n",
      "12:48:47 INFO - __call__: Epoch: 47 Average loss per image: 162.50\n",
      "12:50:15 INFO - __call__: Epoch: 48 Average loss per image: 162.46\n",
      "12:51:39 INFO - __call__: Epoch: 49 Average loss per image: 162.39\n",
      "12:53:05 INFO - __call__: Epoch: 50 Average loss per image: 162.29\n",
      "12:53:05 INFO - __call__: Finished training after 70.7 min.\n",
      "12:53:05 INFO - __init__: Testing Device: cuda\n",
      "12:53:05 INFO - __call__: Computing losses...\n",
      "12:53:06 INFO - __call__: Losses: {'recon_loss': 1.908416748046875, 'loss': 3.0660695393880206, 'mi_loss': 1.1518112182617188, 'tc_loss': -0.5779362360636393, 'dw_kl_loss': 0.00584146777788798, 'kl_loss': 0.4966891606648763, 'kl_loss_0': 0.05060628652572632, 'kl_loss_1': 0.048229595025380455, 'kl_loss_2': 0.04773189624150594, 'kl_loss_3': 0.04962790012359619, 'kl_loss_4': 0.04788453578948974, 'kl_loss_5': 0.05007226864496867, 'kl_loss_6': 0.04903593858083089, 'kl_loss_7': 0.052153484026590986, 'kl_loss_8': 0.051353641351064044, 'kl_loss_9': 0.049993630250295004}\n",
      "12:53:06 INFO - __call__: Finished evaluating after 0.0 min.\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate model\n",
    "vae_trim.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected idcs: [50997, 28883, 7657, 490, 5940, 59701, 52887, 38156, 2288, 44011, 45422, 5500, 6450, 50232, 23241, 15519, 1142, 2019, 51693, 1038, 22681, 42488, 40847, 31735, 40358, 30379, 9735, 5982, 11999, 46754, 7498, 55400, 958, 32970, 31899, 57702, 16372, 4231, 43729, 35460, 59789, 30533, 4493, 39417, 44245, 5828, 33753, 37945, 3012, 17667, 54026, 36466, 4133, 42246, 19819, 31525, 55717, 23280, 17462, 16328, 42957, 13109, 29713, 57445, 34744, 43608, 1264, 33298, 4626, 378, 21856, 9422, 46531, 30987, 43080, 24729, 10951, 3550, 4996, 38504, 32543, 10748, 4936, 36525, 14096, 9453, 1777, 22690, 50526, 7267, 34713, 9255, 43942, 20014, 29762, 2594, 27279, 18139, 43410, 52855]\n"
     ]
    }
   ],
   "source": [
    "# generate visualization\n",
    "args = vae_trim_viz.parse_arguments()\n",
    "args.name = name\n",
    "args.plots = \"all\"\n",
    "args.n_rows = 10\n",
    "args.n_cols = 10\n",
    "vae_trim_viz.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"VAE\"\n",
    "args.name = name\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, labels = iter(test_loader).next()\n",
    "# inputs = inputs.to(device)\n",
    "# labels = labels.to(device)\n",
    "# recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "# s, _ = latent_dist\n",
    "# s = s.detach()\n",
    "\n",
    "# loss_f = get_loss_f(args.loss,\n",
    "#                     n_data=len(test_loader.dataset),\n",
    "#                     device=device,\n",
    "#                     **vars(args))\n",
    "# storer = defaultdict(list)\n",
    "# loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "#                    storer, latent_sample=latent_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recon_loss': 11.618922424316406, 'kl_loss': 2.9720155715942385, 'kl_loss_0': 0.30269935131073, 'kl_loss_1': 0.28816895484924315, 'kl_loss_2': 0.28763034343719485, 'kl_loss_3': 0.2977740287780762, 'kl_loss_4': 0.29319636821746825, 'kl_loss_5': 0.2898214101791382, 'kl_loss_6': 0.30013489723205566, 'kl_loss_7': 0.3069141149520874, 'kl_loss_8': 0.30695381164550783, 'kl_loss_9': 0.2987224102020264, 'loss': 14.59093780517578}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# loss\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(test_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "\n",
    "# evaluate on testset\n",
    "storer = defaultdict(list)\n",
    "for data, _ in tqdm(test_loader, leave=False, disable=args.no_progress_bar):\n",
    "    data = data.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(data)\n",
    "    _ = loss_f(data, recon_batch, latent_dist, model.training,\n",
    "                    storer, latent_sample=latent_sample)    \n",
    "    losses = {k: sum(v) / len(test_loader) for k, v in storer.items()}\n",
    "    break\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
