{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "from model_mnist import LeNet5\n",
    "from visualize import *\n",
    "import dset_mnist as dset\n",
    "import foolbox\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# disentangled vae\n",
    "sys.path.append('../disentangling-vae')\n",
    "from collections import defaultdict\n",
    "import vae_trim, vae_trim_viz\n",
    "from disvae.utils.modelIO import save_model, load_model, load_metadata\n",
    "from disvae.models.losses import get_loss_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.btcvae_B = 3\n",
    "args.reg_anneal = 0\n",
    "args.trim_lamb = 10\n",
    "name = \"disvae_btcvae_B_\" + str(args.btcvae_B) + \"_lamb_\" + str(args.trim_lamb)\n",
    "args.name = name\n",
    "\n",
    "# load classifier\n",
    "m = LeNet5().eval()\n",
    "m.load_state_dict(torch.load('weights/lenet_epoch=12_test_acc=0.991.pth'))\n",
    "m = m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:03:53 INFO - main: Root directory for saving and loading experiments: results/disvae_btcvae_B_3_lamb_10\n",
      "08:03:53 INFO - main: Train mnist with 60000 samples\n",
      "08:03:53 INFO - main: Num parameters in model: 469173\n",
      "08:03:53 INFO - __init__: Training Device: cuda\n",
      "08:04:25 INFO - __call__: Epoch: 1 Average loss per image: 151.97\n",
      "08:04:56 INFO - __call__: Epoch: 2 Average loss per image: 115.05\n",
      "08:05:26 INFO - __call__: Epoch: 3 Average loss per image: 110.29\n",
      "08:05:56 INFO - __call__: Epoch: 4 Average loss per image: 107.85\n",
      "08:06:27 INFO - __call__: Epoch: 5 Average loss per image: 106.11\n",
      "08:06:58 INFO - __call__: Epoch: 6 Average loss per image: 104.86\n",
      "08:07:30 INFO - __call__: Epoch: 7 Average loss per image: 104.01\n",
      "08:08:00 INFO - __call__: Epoch: 8 Average loss per image: 103.15\n",
      "08:08:31 INFO - __call__: Epoch: 9 Average loss per image: 102.45\n",
      "08:09:01 INFO - __call__: Epoch: 10 Average loss per image: 101.90\n",
      "08:09:33 INFO - __call__: Epoch: 11 Average loss per image: 101.32\n",
      "08:10:05 INFO - __call__: Epoch: 12 Average loss per image: 100.88\n",
      "08:10:37 INFO - __call__: Epoch: 13 Average loss per image: 100.33\n",
      "08:11:09 INFO - __call__: Epoch: 14 Average loss per image: 99.96\n",
      "08:11:39 INFO - __call__: Epoch: 15 Average loss per image: 99.65\n",
      "08:12:10 INFO - __call__: Epoch: 16 Average loss per image: 99.34\n",
      "08:12:42 INFO - __call__: Epoch: 17 Average loss per image: 98.99\n",
      "08:13:14 INFO - __call__: Epoch: 18 Average loss per image: 98.75\n",
      "08:13:45 INFO - __call__: Epoch: 19 Average loss per image: 98.43\n",
      "08:14:16 INFO - __call__: Epoch: 20 Average loss per image: 98.19\n",
      "08:14:48 INFO - __call__: Epoch: 21 Average loss per image: 98.11\n",
      "08:15:18 INFO - __call__: Epoch: 22 Average loss per image: 97.77\n",
      "08:15:50 INFO - __call__: Epoch: 23 Average loss per image: 97.63\n",
      "08:16:23 INFO - __call__: Epoch: 24 Average loss per image: 97.41\n",
      "08:16:54 INFO - __call__: Epoch: 25 Average loss per image: 97.21\n",
      "08:17:26 INFO - __call__: Epoch: 26 Average loss per image: 97.04\n",
      "08:17:56 INFO - __call__: Epoch: 27 Average loss per image: 96.89\n",
      "08:18:26 INFO - __call__: Epoch: 28 Average loss per image: 96.77\n",
      "08:18:56 INFO - __call__: Epoch: 29 Average loss per image: 96.64\n",
      "08:19:28 INFO - __call__: Epoch: 30 Average loss per image: 96.45\n",
      "08:20:00 INFO - __call__: Epoch: 31 Average loss per image: 96.35\n",
      "08:20:31 INFO - __call__: Epoch: 32 Average loss per image: 96.17\n",
      "08:21:01 INFO - __call__: Epoch: 33 Average loss per image: 96.11\n",
      "08:21:32 INFO - __call__: Epoch: 34 Average loss per image: 96.01\n",
      "08:22:04 INFO - __call__: Epoch: 35 Average loss per image: 95.87\n",
      "08:22:36 INFO - __call__: Epoch: 36 Average loss per image: 95.70\n",
      "08:23:07 INFO - __call__: Epoch: 37 Average loss per image: 95.60\n",
      "08:23:38 INFO - __call__: Epoch: 38 Average loss per image: 95.54\n",
      "08:24:09 INFO - __call__: Epoch: 39 Average loss per image: 95.47\n",
      "08:24:39 INFO - __call__: Epoch: 40 Average loss per image: 95.36\n",
      "Epoch 41:  37%|███▋      | 348/938 [00:11<00:18, 31.16it/s, loss=87.1]"
     ]
    }
   ],
   "source": [
    "# train and evaluate model\n",
    "vae_trim.main(args, classifier=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate visualization\n",
    "args = vae_trim_viz.parse_arguments()\n",
    "args.name = name\n",
    "args.plots = \"all\"\n",
    "args.n_rows = 10\n",
    "args.n_cols = 10\n",
    "vae_trim_viz.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.name = name\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(test_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "\n",
    "# evaluate on testset\n",
    "storer = defaultdict(list)\n",
    "for data, _ in tqdm(test_loader, leave=False, disable=args.no_progress_bar):\n",
    "    data = data.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(data)\n",
    "    _ = loss_f(data, recon_batch, latent_dist, model.training,\n",
    "                    storer, latent_sample=latent_sample)    \n",
    "    losses = {k: sum(v) / len(test_loader) for k, v in storer.items()}\n",
    "    break\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
