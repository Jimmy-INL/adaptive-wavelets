{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "from model_mnist import LeNet5\n",
    "from visualize import *\n",
    "import dset_mnist as dset\n",
    "import foolbox\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# disentangled vae\n",
    "sys.path.append('../disentangling-vae')\n",
    "from collections import defaultdict\n",
    "import vae_trim, vae_trim_viz\n",
    "from disvae.utils.modelIO import save_model, load_model, load_metadata\n",
    "from disvae.models.losses import get_loss_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 1\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B) \n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_numer_norm = (jacob_norm**2).sum(axis=(1,2))\n",
    "# d_denom_norm = (jacob_norm.sum(axis=2)**2).sum(axis=1)\n",
    "# diversity_norm = d_numer_norm / d_denom_norm\n",
    "# print(diversity_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 3\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B) \n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = iter(train_loader).next()\n",
    "inputs = inputs.to(device)\n",
    "reconstruct, (mu, _), latent_sample = model(inputs)\n",
    "mu1, _ = model.encoder(model.decoder(mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0205,  0.0102,  0.1553,  0.1051, -0.0485, -0.0690,  0.1608, -0.0537,\n",
       "        -0.0519, -0.6313], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[0] - mu1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7764, -1.2664,  0.4404,  0.8765,  0.8272, -0.6060,  0.6523, -2.1265,\n",
       "         0.5820, -0.7629], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0473, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2Loss(mu[0], mu1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2Loss(inputs[0], reconstruct[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1397e-04, -2.8976e-06, -9.4455e-07,  ..., -5.7852e-08,\n",
       "          -1.1602e-07, -3.4971e-06],\n",
       "         [-3.2469e-06, -6.2790e-08, -4.1766e-08,  ..., -1.3718e-09,\n",
       "          -2.1955e-09, -9.4979e-08],\n",
       "         [-8.4504e-07, -2.5969e-08, -6.6165e-08,  ..., -1.5370e-09,\n",
       "          -1.4356e-09, -3.8364e-08],\n",
       "         ...,\n",
       "         [-1.9642e-06, -6.8343e-07, -1.7307e-06,  ..., -6.6742e-08,\n",
       "          -2.2769e-08, -1.1515e-07],\n",
       "         [-4.7090e-06, -1.1423e-06, -4.3639e-07,  ..., -1.2553e-07,\n",
       "          -9.2595e-08, -8.8304e-07],\n",
       "         [-1.3147e-05, -2.0535e-07, -4.4770e-08,  ..., -7.5609e-08,\n",
       "          -2.1745e-07, -8.9945e-06]]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0] - reconstruct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, _ = model.encoder(model.decoder(latent_dist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f556244ac88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inputs.detach().cpu().numpy()[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5564706b70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reconstruct.detach().cpu().numpy()[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 6\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B) \n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 9\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B) \n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 12\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B) \n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-1-attr-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 12\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = \"btcvae_B_1_attr_20_latent_sample_use_residuals\"\n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-1-attr-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 12\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = \"btcvae_B_1_attr_60_latent_sample_use_residuals\"\n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-3-attr-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 12\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = \"btcvae_B_3_attr_60_latent_sample_use_residuals\"\n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-3-attr-60-L1norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 12\n",
    "args.attr_lamb = 0\n",
    "args.epochs = 100\n",
    "name = \"btcvae_B_3_attr_60_latent_sample_use_residuals_L1norm\"\n",
    "args.name = name\n",
    "\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.batch_size, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "latent_map = DecoderEncoder(model, use_residuals=True)\n",
    "\n",
    "L2Loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = 0\n",
    "Diversity = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = latent_map(s, deepcopy(inputs))\n",
    "    loss = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradients_pairwise = gradients[:,col_idx]\n",
    "        loss += L2Loss(gradients_pairwise, torch.zeros_like(gradients_pairwise))\n",
    "    Loss += loss.item()\n",
    "    \n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    x = model.decoder(s)\n",
    "\n",
    "    grad = []\n",
    "    for i in range(32*32):\n",
    "        gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "        grad.append(gradients)\n",
    "\n",
    "    jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "    jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "    d_numer = (jacob**2).sum(axis=(1,2))\n",
    "    d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "    diversity = d_numer / d_denom    \n",
    "    Diversity += diversity.sum().item()\n",
    "    \n",
    "    print('\\rIndex: {}/{}'.format(batch_idx+1, len(test_loader)), end='')\n",
    "\n",
    "print('\\n Loss: {}'.format(Loss))\n",
    "print('\\n Diversity: {}'.format(Diversity/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if self.attr_lamb > 0:\n",
    "#     s = deepcopy(latent_sample.detach())\n",
    "#     s = s.requires_grad_(True)\n",
    "#     x = self.model.decoder(s)\n",
    "#     grad = []\n",
    "#     for i in range(32*32):\n",
    "#         gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "#                                         retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "#         grad.append(gradients)\n",
    "\n",
    "#     jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "#     d_numer = (jacob**2).sum(axis=(1,2))\n",
    "#     d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "#     diversity = d_numer / d_denom   \n",
    "#     loss += self.attr_lamb/batch_size * torch.norm(diversity - 1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "Loss = 0\n",
    "Diversity = 0\n",
    "inputs, labels = iter(test_loader).next()\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "s = deepcopy(latent_dist[0].detach())\n",
    "s = s.requires_grad_(True)\n",
    "x = model.decoder(s)\n",
    "\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = []\n",
    "for i in range(32*32):\n",
    "    gradients = torch.autograd.grad(x.view(-1,32*32)[:,i], s, grad_outputs=torch.ones_like(x.view(-1,32*32)[:,i]), \n",
    "                                    retain_graph=True, create_graph=True, only_inputs=True)[0]    \n",
    "    grad.append(gradients)\n",
    "\n",
    "jacob = torch.stack(grad).permute(1, 0, 2)\n",
    "jacob_norm = jacob / torch.norm(jacob, dim=1).unsqueeze(1) \n",
    "d_numer = (jacob**2).sum(axis=(1,2))\n",
    "d_denom = (jacob.sum(axis=2)**2).sum(axis=1)\n",
    "diversity = d_numer / d_denom    \n",
    "(torch.norm(diversity - 1)**2).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = deepcopy(latent_sample.detach())\n",
    "s = s.requires_grad_(True)\n",
    "x = model.decoder(s)\n",
    "\n",
    "eps = 1e-5\n",
    "e = torch.eye(s.shape[1]).to(device)\n",
    "\n",
    "grad = []\n",
    "for i in range(s.shape[1]):\n",
    "    x_shift = model.decoder(s + eps*e[i])\n",
    "    grad.append((x_shift - x)/eps)\n",
    "grad = torch.stack(grad).permute(1,2,3,4,0).view(64,32*32,10)\n",
    "\n",
    "x_shift1 = model.decoder(s + eps*e[0])\n",
    "x_shift2 = model.decoder(s + eps*e[1])       \n",
    "\n",
    "grad1 = (x_shift1 - x)/eps\n",
    "grad2 = (x_shift2 - x)/eps \n",
    "\n",
    "((grad1 * grad2).sum(axis=(1,2,3))**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = deepcopy(latent_sample.detach())\n",
    "s = s.requires_grad_(True)\n",
    "x = model.decoder(s)\n",
    "batch_size = s.shape[0]\n",
    "\n",
    "eps = 1e-5\n",
    "e = torch.eye(s.shape[1]).to(device)\n",
    "\n",
    "grad = []\n",
    "for i in range(s.shape[1]):\n",
    "    x_shift = model.decoder(s + eps*e[i])\n",
    "    grad.append((x_shift - x)/eps)\n",
    "grad = torch.stack(grad).permute(1,2,3,4,0).view(batch_size,32*32,10)   \n",
    "\n",
    "a = torch.matmul(grad.permute(0,2,1),grad)\n",
    "ind = np.diag_indices(s.shape[1])\n",
    "a[:, ind[0], ind[1]] = torch.zeros(s.shape[1]).to(device)                              \n",
    "print((a**2).sum()/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = deepcopy(latent_sample.detach())\n",
    "s = s.requires_grad_(True)\n",
    "batch_size = s.shape[0]\n",
    "\n",
    "eps = 1e-5\n",
    "e = torch.eye(s.shape[1]).to(device)\n",
    "\n",
    "grad = []\n",
    "for i in range(s.shape[1]):\n",
    "    x_shift = model.decoder(s + 0.5*eps*e[i])\n",
    "    x = model.decoder(s - 0.5*eps*e[i])\n",
    "    grad.append((x_shift - x)/eps)\n",
    "grad = torch.stack(grad).permute(1,2,3,4,0).view(batch_size,32*32,10)   \n",
    "\n",
    "a = torch.matmul(grad.permute(0,2,1),grad)\n",
    "ind = np.diag_indices(s.shape[1])\n",
    "a[:, ind[0], ind[1]] = torch.zeros(s.shape[1]).to(device)                              \n",
    "print((a**2).sum()/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.matmul(jacob.permute(0,2,1),jacob)\n",
    "ind = np.diag_indices(s.shape[1])\n",
    "a[:, ind[0], ind[1]] = torch.zeros(s.shape[1]).to(device)                              \n",
    "print((a**2).sum()/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.matmul(jacob.permute(0,2,1),jacob)\n",
    "ind = np.diag_indices(s.shape[1])\n",
    "print(((a**2).sum() - (a[:,ind[0],ind[1]]**2).sum())/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.diag(tor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.matmul(grad.permute(0,2,1),grad)[:,0,1]**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.matmul(grad.permute(0,2,1),grad)\n",
    "ind = np.diag_indices(s.shape[1])\n",
    "a[:, ind[0], ind[1]] = torch.zeros(s.shape[1]).to(device)\n",
    "(a**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ = model.encoder(model.decoder(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
