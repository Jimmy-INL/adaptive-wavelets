{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "from model_mnist import LeNet5\n",
    "from visualize import *\n",
    "import dset_mnist as dset\n",
    "import foolbox\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# disentangled vae\n",
    "sys.path.append('../disentangling-vae')\n",
    "from collections import defaultdict\n",
    "import vae_trim, vae_trim_viz\n",
    "from disvae.utils.modelIO import save_model, load_model, load_metadata\n",
    "from disvae.models.losses import get_loss_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-Attr-Pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 0\n",
    "args.attr_lamb = 10\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B) + \"_attr_\" + str(args.attr_lamb)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.name = name\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "\n",
    "# L1Loss\n",
    "L1Loss = torch.nn.L1Loss()\n",
    "\n",
    "# saliency map\n",
    "saliency = InputXGradient(DecoderEncoder(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = iter(test_loader).next()\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(test_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "storer = defaultdict(list)\n",
    "loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                   storer, latent_sample=latent_sample)\n",
    "\n",
    "loss = 0\n",
    "s = deepcopy(latent_dist[0].detach())\n",
    "# s = deepcopy(latent_sample.detach())\n",
    "for i in range(model.latent_dim):\n",
    "    col_idx = np.arange(model.latent_dim)!=i\n",
    "    attributions = torch.div(saliency.attribute(s, target=i),s)[:,col_idx]\n",
    "#     attributions = saliency.attribute(s, target=i)[:,col_idx]\n",
    "    loss += L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1019, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1021, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 3\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.name = name\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "\n",
    "# L1Loss\n",
    "L1Loss = torch.nn.L1Loss()\n",
    "\n",
    "# saliency map\n",
    "saliency = InputXGradient(DecoderEncoder(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = iter(test_loader).next()\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(test_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "storer = defaultdict(list)\n",
    "loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                   storer, latent_sample=latent_sample)\n",
    "\n",
    "loss = 0\n",
    "s = deepcopy(latent_dist[0].detach())\n",
    "for i in range(model.latent_dim):\n",
    "    col_idx = np.arange(model.latent_dim)!=i\n",
    "#     attributions = torch.div(saliency.attribute(s, target=i),s)[:,col_idx]\n",
    "    attributions = saliency.attribute(s, target=i)[:,col_idx]\n",
    "    loss += L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1394, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8201, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 6\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.name = name\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "\n",
    "# L1Loss\n",
    "L1Loss = torch.nn.L1Loss()\n",
    "\n",
    "# saliency map\n",
    "saliency = InputXGradient(DecoderEncoder(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = iter(test_loader).next()\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(test_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "storer = defaultdict(list)\n",
    "loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                   storer, latent_sample=latent_sample)\n",
    "\n",
    "loss = 0\n",
    "s = deepcopy(latent_dist[0].detach())\n",
    "for i in range(model.latent_dim):\n",
    "    col_idx = np.arange(model.latent_dim)!=i\n",
    "    attributions = torch.div(saliency.attribute(s, target=i),s)[:,col_idx]\n",
    "#     attributions = saliency.attribute(s, target=i)[:,col_idx]\n",
    "    loss += L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0091, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6944, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTCVAE-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.reg_anneal = 0\n",
    "args.btcvae_B = 12\n",
    "name = args.loss + \"_B_\" + str(args.btcvae_B)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"btcvae\"\n",
    "args.name = name\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)\n",
    "\n",
    "# L1Loss\n",
    "L1Loss = torch.nn.L1Loss()\n",
    "\n",
    "# saliency map\n",
    "saliency = InputXGradient(DecoderEncoder(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = iter(test_loader).next()\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(test_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "storer = defaultdict(list)\n",
    "loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                   storer, latent_sample=latent_sample)\n",
    "\n",
    "loss = 0\n",
    "s = deepcopy(latent_dist[0].detach())\n",
    "for i in range(model.latent_dim):\n",
    "    col_idx = np.arange(model.latent_dim)!=i\n",
    "    attributions = torch.div(saliency.attribute(s, target=i),s)[:,col_idx]\n",
    "#     attributions = saliency.attribute(s, target=i)[:,col_idx]\n",
    "    loss += L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0893, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Loss(attributions, torch.zeros_like(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
