{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "from model_mnist import LeNet5\n",
    "from visualize import *\n",
    "import dset_mnist as dset\n",
    "import foolbox\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# disentangled vae\n",
    "sys.path.append('../disentangling-vae')\n",
    "from collections import defaultdict\n",
    "import vae_trim, vae_trim_viz\n",
    "from disvae.utils.modelIO import save_model, load_model, load_metadata\n",
    "from disvae.models.losses import get_loss_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.btcvae_B = 3\n",
    "args.reg_anneal = 0\n",
    "name = \"disvae_btcvae_B_\" + str(args.btcvae_B)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:42:26 INFO - main: Root directory for saving and loading experiments: results/disvae_btcvae_B_3\n",
      "04:42:26 INFO - main: Train mnist with 60000 samples\n",
      "04:42:26 INFO - main: Num parameters in model: 469173\n",
      "04:42:28 INFO - __init__: Training Device: cuda\n",
      "04:42:50 INFO - __call__: Epoch: 1 Average loss per image: 143.72\n",
      "04:43:11 INFO - __call__: Epoch: 2 Average loss per image: 108.05\n",
      "04:43:33 INFO - __call__: Epoch: 3 Average loss per image: 103.30\n",
      "04:43:56 INFO - __call__: Epoch: 4 Average loss per image: 100.88\n",
      "04:44:18 INFO - __call__: Epoch: 5 Average loss per image: 99.09\n",
      "04:44:39 INFO - __call__: Epoch: 6 Average loss per image: 97.88\n",
      "04:45:01 INFO - __call__: Epoch: 7 Average loss per image: 96.93\n",
      "04:45:23 INFO - __call__: Epoch: 8 Average loss per image: 96.13\n",
      "04:45:44 INFO - __call__: Epoch: 9 Average loss per image: 95.44\n",
      "04:46:06 INFO - __call__: Epoch: 10 Average loss per image: 94.87\n",
      "04:46:29 INFO - __call__: Epoch: 11 Average loss per image: 94.29\n",
      "04:46:54 INFO - __call__: Epoch: 12 Average loss per image: 93.87\n",
      "04:47:18 INFO - __call__: Epoch: 13 Average loss per image: 93.43\n",
      "04:47:42 INFO - __call__: Epoch: 14 Average loss per image: 93.04\n",
      "04:48:07 INFO - __call__: Epoch: 15 Average loss per image: 92.68\n",
      "04:48:30 INFO - __call__: Epoch: 16 Average loss per image: 92.36\n",
      "04:48:52 INFO - __call__: Epoch: 17 Average loss per image: 92.02\n",
      "04:49:13 INFO - __call__: Epoch: 18 Average loss per image: 91.78\n",
      "04:49:36 INFO - __call__: Epoch: 19 Average loss per image: 91.53\n",
      "04:49:58 INFO - __call__: Epoch: 20 Average loss per image: 91.22\n",
      "04:50:20 INFO - __call__: Epoch: 21 Average loss per image: 91.04\n",
      "04:50:43 INFO - __call__: Epoch: 22 Average loss per image: 90.88\n",
      "04:51:04 INFO - __call__: Epoch: 23 Average loss per image: 90.72\n",
      "04:51:27 INFO - __call__: Epoch: 24 Average loss per image: 90.42\n",
      "04:51:49 INFO - __call__: Epoch: 25 Average loss per image: 90.27\n",
      "04:52:13 INFO - __call__: Epoch: 26 Average loss per image: 90.12\n",
      "04:52:37 INFO - __call__: Epoch: 27 Average loss per image: 90.01\n",
      "04:53:01 INFO - __call__: Epoch: 28 Average loss per image: 89.83\n",
      "04:53:23 INFO - __call__: Epoch: 29 Average loss per image: 89.64\n",
      "04:53:45 INFO - __call__: Epoch: 30 Average loss per image: 89.51\n",
      "04:54:07 INFO - __call__: Epoch: 31 Average loss per image: 89.42\n",
      "04:54:29 INFO - __call__: Epoch: 32 Average loss per image: 89.29\n",
      "04:54:51 INFO - __call__: Epoch: 33 Average loss per image: 89.18\n",
      "04:55:13 INFO - __call__: Epoch: 34 Average loss per image: 89.06\n",
      "04:55:36 INFO - __call__: Epoch: 35 Average loss per image: 88.95\n",
      "04:55:58 INFO - __call__: Epoch: 36 Average loss per image: 88.91\n",
      "04:56:20 INFO - __call__: Epoch: 37 Average loss per image: 88.73\n",
      "04:56:41 INFO - __call__: Epoch: 38 Average loss per image: 88.70\n",
      "04:57:02 INFO - __call__: Epoch: 39 Average loss per image: 88.60\n",
      "04:57:24 INFO - __call__: Epoch: 40 Average loss per image: 88.49\n",
      "04:57:46 INFO - __call__: Epoch: 41 Average loss per image: 88.36\n",
      "04:58:07 INFO - __call__: Epoch: 42 Average loss per image: 88.31\n",
      "04:58:29 INFO - __call__: Epoch: 43 Average loss per image: 88.25\n",
      "04:58:50 INFO - __call__: Epoch: 44 Average loss per image: 88.14\n",
      "04:59:11 INFO - __call__: Epoch: 45 Average loss per image: 88.07\n",
      "04:59:32 INFO - __call__: Epoch: 46 Average loss per image: 88.01\n",
      "04:59:53 INFO - __call__: Epoch: 47 Average loss per image: 87.91\n",
      "05:00:14 INFO - __call__: Epoch: 48 Average loss per image: 87.93\n",
      "05:00:35 INFO - __call__: Epoch: 49 Average loss per image: 87.82\n",
      "05:00:56 INFO - __call__: Epoch: 50 Average loss per image: 87.76\n",
      "05:01:18 INFO - __call__: Epoch: 51 Average loss per image: 87.72\n",
      "05:01:40 INFO - __call__: Epoch: 52 Average loss per image: 87.63\n",
      "05:02:01 INFO - __call__: Epoch: 53 Average loss per image: 87.56\n",
      "05:02:23 INFO - __call__: Epoch: 54 Average loss per image: 87.50\n",
      "05:02:45 INFO - __call__: Epoch: 55 Average loss per image: 87.46\n",
      "05:03:07 INFO - __call__: Epoch: 56 Average loss per image: 87.37\n",
      "05:03:29 INFO - __call__: Epoch: 57 Average loss per image: 87.29\n",
      "05:03:50 INFO - __call__: Epoch: 58 Average loss per image: 87.31\n",
      "05:04:12 INFO - __call__: Epoch: 59 Average loss per image: 87.21\n",
      "05:04:35 INFO - __call__: Epoch: 60 Average loss per image: 87.13\n",
      "05:04:56 INFO - __call__: Epoch: 61 Average loss per image: 87.16\n",
      "05:05:17 INFO - __call__: Epoch: 62 Average loss per image: 87.10\n",
      "05:05:38 INFO - __call__: Epoch: 63 Average loss per image: 87.05\n",
      "05:05:59 INFO - __call__: Epoch: 64 Average loss per image: 86.97\n",
      "05:06:20 INFO - __call__: Epoch: 65 Average loss per image: 86.99\n",
      "05:06:42 INFO - __call__: Epoch: 66 Average loss per image: 86.92\n",
      "05:07:03 INFO - __call__: Epoch: 67 Average loss per image: 86.87\n",
      "05:07:26 INFO - __call__: Epoch: 68 Average loss per image: 86.78\n",
      "05:07:47 INFO - __call__: Epoch: 69 Average loss per image: 86.79\n",
      "05:08:10 INFO - __call__: Epoch: 70 Average loss per image: 86.68\n",
      "05:08:32 INFO - __call__: Epoch: 71 Average loss per image: 86.68\n",
      "05:08:53 INFO - __call__: Epoch: 72 Average loss per image: 86.63\n",
      "05:09:14 INFO - __call__: Epoch: 73 Average loss per image: 86.63\n",
      "05:09:35 INFO - __call__: Epoch: 74 Average loss per image: 86.62\n",
      "05:09:56 INFO - __call__: Epoch: 75 Average loss per image: 86.64\n",
      "05:10:19 INFO - __call__: Epoch: 76 Average loss per image: 86.52\n",
      "05:10:41 INFO - __call__: Epoch: 77 Average loss per image: 86.52\n",
      "05:11:02 INFO - __call__: Epoch: 78 Average loss per image: 86.39\n",
      "05:11:25 INFO - __call__: Epoch: 79 Average loss per image: 86.44\n",
      "05:11:46 INFO - __call__: Epoch: 80 Average loss per image: 86.34\n",
      "05:12:07 INFO - __call__: Epoch: 81 Average loss per image: 86.33\n",
      "05:12:28 INFO - __call__: Epoch: 82 Average loss per image: 86.34\n",
      "05:12:49 INFO - __call__: Epoch: 83 Average loss per image: 86.26\n",
      "05:13:10 INFO - __call__: Epoch: 84 Average loss per image: 86.28\n",
      "05:13:33 INFO - __call__: Epoch: 85 Average loss per image: 86.27\n",
      "05:13:54 INFO - __call__: Epoch: 86 Average loss per image: 86.11\n",
      "05:14:15 INFO - __call__: Epoch: 87 Average loss per image: 86.14\n",
      "05:14:36 INFO - __call__: Epoch: 88 Average loss per image: 86.13\n",
      "05:14:57 INFO - __call__: Epoch: 89 Average loss per image: 86.08\n",
      "05:15:18 INFO - __call__: Epoch: 90 Average loss per image: 86.12\n",
      "05:15:39 INFO - __call__: Epoch: 91 Average loss per image: 86.05\n",
      "05:16:00 INFO - __call__: Epoch: 92 Average loss per image: 86.00\n",
      "05:16:23 INFO - __call__: Epoch: 93 Average loss per image: 85.96\n",
      "05:16:44 INFO - __call__: Epoch: 94 Average loss per image: 85.92\n",
      "05:17:06 INFO - __call__: Epoch: 95 Average loss per image: 85.94\n",
      "05:17:30 INFO - __call__: Epoch: 96 Average loss per image: 85.84\n",
      "05:17:51 INFO - __call__: Epoch: 97 Average loss per image: 85.92\n",
      "05:18:11 INFO - __call__: Epoch: 98 Average loss per image: 85.84\n",
      "05:18:32 INFO - __call__: Epoch: 99 Average loss per image: 85.75\n",
      "05:18:54 INFO - __call__: Epoch: 100 Average loss per image: 85.78\n",
      "05:18:55 INFO - __call__: Finished training after 36.4 min.\n",
      "05:18:55 INFO - __init__: Testing Device: cuda\n",
      "05:18:55 INFO - __call__: Computing losses...\n",
      "05:18:55 INFO - __call__: Losses: {'recon_loss': 1.9935860951741537, 'loss': 0.5144920349121094, 'mi_loss': 1.1511583964029948, 'tc_loss': -0.8802115758260091, 'dw_kl_loss': 0.010382259885470072, 'kl_loss': 0.21345842679341634, 'kl_loss_0': 0.03631333510080973, 'kl_loss_1': 0.029879228274027506, 'kl_loss_2': 0.015127625068028767, 'kl_loss_3': 0.02445124586423238, 'kl_loss_4': 0.013617055614789327, 'kl_loss_5': 0.03766562541325887, 'kl_loss_6': 0.016752129793167113, 'kl_loss_7': 0.024327687422434487, 'kl_loss_8': 0.009517800807952882, 'kl_loss_9': 0.00580669641494751}\n",
      "05:18:55 INFO - __call__: Finished evaluating after 0.0 min.\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate model\n",
    "vae_trim.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected idcs: [50997, 28883, 7657, 490, 5940, 59701, 52887, 38156, 2288, 44011, 45422, 5500, 6450, 50232, 23241, 15519, 1142, 2019, 51693, 1038, 22681, 42488, 40847, 31735, 40358, 30379, 9735, 5982, 11999, 46754, 7498, 55400, 958, 32970, 31899, 57702, 16372, 4231, 43729, 35460, 59789, 30533, 4493, 39417, 44245, 5828, 33753, 37945, 3012, 17667, 54026, 36466, 4133, 42246, 19819, 31525, 55717, 23280, 17462, 16328, 42957, 13109, 29713, 57445, 34744, 43608, 1264, 33298, 4626, 378, 21856, 9422, 46531, 30987, 43080, 24729, 10951, 3550, 4996, 38504, 32543, 10748, 4936, 36525, 14096, 9453, 1777, 22690, 50526, 7267, 34713, 9255, 43942, 20014, 29762, 2594, 27279, 18139, 43410, 52855]\n"
     ]
    }
   ],
   "source": [
    "# generate visualization\n",
    "args = vae_trim_viz.parse_arguments()\n",
    "args.name = name\n",
    "args.plots = \"all\"\n",
    "args.n_rows = 10\n",
    "args.n_cols = 10\n",
    "vae_trim_viz.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.name = name\n",
    "# results dir\n",
    "exp_dir = os.path.join(vae_trim.RES_DIR, args.name)\n",
    "\n",
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "metadata = load_metadata(exp_dir)\n",
    "\n",
    "# load model\n",
    "model = load_model(exp_dir, is_gpu=not args.no_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recon_loss': 12.077007293701172, 'loss': -12.449819183349609, 'mi_loss': 6.902687835693359, 'tc_loss': -5.24765625, 'dw_kl_loss': 0.05642252564430237, 'kl_loss': 1.3029804229736328, 'kl_loss_0': 0.22331509590148926, 'kl_loss_1': 0.17529566287994386, 'kl_loss_2': 0.10838617086410522, 'kl_loss_3': 0.14502040147781373, 'kl_loss_4': 0.09416732788085938, 'kl_loss_5': 0.2068561792373657, 'kl_loss_6': 0.09928142428398132, 'kl_loss_7': 0.1502346396446228, 'kl_loss_8': 0.06066139936447144, 'kl_loss_9': 0.03976207971572876}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# loss\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(test_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "\n",
    "# evaluate on testset\n",
    "storer = defaultdict(list)\n",
    "for data, _ in tqdm(test_loader, leave=False, disable=args.no_progress_bar):\n",
    "    data = data.to(device)\n",
    "    recon_batch, latent_dist, latent_sample = model(data)\n",
    "    _ = loss_f(data, recon_batch, latent_dist, model.training,\n",
    "                    storer, latent_sample=latent_sample)    \n",
    "    losses = {k: sum(v) / len(test_loader) for k, v in storer.items()}\n",
    "    break\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
