{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "from model_mnist import LeNet5\n",
    "from visualize import *\n",
    "import dset_mnist as dset\n",
    "import foolbox\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# disentangled vae\n",
    "sys.path.append('../disentangling-vae')\n",
    "from collections import defaultdict\n",
    "import vae_trim, vae_trim_viz\n",
    "from disvae.utils.modelIO import save_model, load_model, load_metadata\n",
    "from disvae.models.losses import get_loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disvae import init_specific_model\n",
    "from utils.datasets import get_img_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE-Attr-Pen-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"VAE\"\n",
    "args.reg_anneal = 0\n",
    "args.attr_lamb = 1 # change of attribute wrt other attributes\n",
    "# name = args.loss + \"_B_\" + str(args.btcvae_B) + \"_attr_\" + str(args.attr_lamb)\n",
    "name = args.loss + \"_attr_\" + str(args.attr_lamb)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "\n",
    "# initialize model\n",
    "args.img_size = get_img_size(args.dataset)\n",
    "model = init_specific_model(args.model_type, args.img_size, args.latent_dim).to(device)\n",
    "\n",
    "# Train\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# loss\n",
    "L1Loss = torch.nn.L1Loss()\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(train_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "\n",
    "m = DecoderEncoder(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [29984/60000 (100%)]\tLoss: 158.294495\n",
      "Average loss: 200.27238618895444 - Average reg: 0.9039921596137954\n",
      "Train Epoch: 1 [29984/60000 (100%)]\tLoss: 167.514496\n",
      "Average loss: 162.65034253866688 - Average reg: 0.9991621267058448\n",
      "Train Epoch: 2 [29984/60000 (100%)]\tLoss: 160.389450\n",
      "Average loss: 158.34996434518777 - Average reg: 0.9760078649912307\n",
      "Train Epoch: 3 [29984/60000 (100%)]\tLoss: 152.696457\n",
      "Average loss: 155.9498725028943 - Average reg: 0.9629841467210734\n",
      "Train Epoch: 4 [29984/60000 (100%)]\tLoss: 142.821411\n",
      "Average loss: 154.39593377347185 - Average reg: 0.9548810851345184\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(5):\n",
    "    epoch_loss = 0\n",
    "    epoch_reg = 0\n",
    "    # one epoch\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)    \n",
    "        batch_size, channel, height, width = inputs.size()\n",
    "        recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "        loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                           None, latent_sample=latent_sample)        \n",
    "        # penalize change in one attribute wrt the other attributes\n",
    "        if args.attr_lamb > 0:\n",
    "            s = deepcopy(latent_dist[0].detach())\n",
    "            s = s.requires_grad_(True)\n",
    "            s_output = m(s)\n",
    "            attr_reg = 0\n",
    "            for i in range(model.latent_dim):\n",
    "                col_idx = np.arange(model.latent_dim)!=i\n",
    "                gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                                retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "                gradient_pairwise = gradients[:,col_idx]\n",
    "                attr_reg += args.attr_lamb * L1Loss(gradient_pairwise, torch.zeros_like(gradient_pairwise))\n",
    "        loss += attr_reg\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_reg += attr_reg.item()      \n",
    "        print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(labels), len(train_loader.dataset),\n",
    "                   100. * batch_idx / len(train_loader), loss.data.item()), end='')        \n",
    "    mean_epoch_loss = epoch_loss / len(train_loader)\n",
    "    mean_epoch_reg = epoch_reg / len(train_loader)\n",
    "    print('\\nAverage loss: {} - Average reg: {}'.format(mean_epoch_loss, mean_epoch_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.3707662879277 0.9546791959418925\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "epoch_loss = 0\n",
    "epoch_reg = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(train_loader):     \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)    \n",
    "    batch_size, channel, height, width = inputs.size()\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                       None, latent_sample=latent_sample)          \n",
    "    # penalize change in one attribute wrt the other attributes\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = m(s)\n",
    "    attr_reg = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradient_pairwise = gradients[:,col_idx]\n",
    "        attr_reg += L1Loss(gradient_pairwise, torch.zeros_like(gradient_pairwise))\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_reg += attr_reg.item()  \n",
    "print(epoch_loss/len(train_loader), epoch_reg/len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE-Attr-Pen-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = vae_trim.parse_arguments()\n",
    "args.loss = \"VAE\"\n",
    "args.reg_anneal = 0\n",
    "args.attr_lamb = 100 # change of attribute wrt other attributes\n",
    "# name = args.loss + \"_B_\" + str(args.btcvae_B) + \"_attr_\" + str(args.attr_lamb)\n",
    "name = args.loss + \"_attr_\" + str(args.attr_lamb)\n",
    "args.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataloaders\n",
    "train_loader, test_loader = dset.load_data(args.batch_size, args.eval_batchsize, device)\n",
    "\n",
    "# initialize model\n",
    "args.img_size = get_img_size(args.dataset)\n",
    "model = init_specific_model(args.model_type, args.img_size, args.latent_dim).to(device)\n",
    "\n",
    "# Train\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# loss\n",
    "L1Loss = torch.nn.L1Loss()\n",
    "loss_f = get_loss_f(args.loss,\n",
    "                    n_data=len(train_loader.dataset),\n",
    "                    device=device,\n",
    "                    **vars(args))\n",
    "\n",
    "m = DecoderEncoder(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [29984/60000 (100%)]\tLoss: 210.608841\n",
      "Average loss: 239.94518593989454 - Average reg: 10.854900648853164\n",
      "Train Epoch: 1 [29984/60000 (100%)]\tLoss: 196.884308\n",
      "Average loss: 201.20241733705566 - Average reg: 7.1664520896065715\n",
      "Train Epoch: 2 [29984/60000 (100%)]\tLoss: 199.069855\n",
      "Average loss: 194.75057225339194 - Average reg: 6.270021577887952\n",
      "Train Epoch: 3 [29984/60000 (100%)]\tLoss: 181.511642\n",
      "Average loss: 190.6632037294953 - Average reg: 5.664612972914283\n",
      "Train Epoch: 4 [29984/60000 (100%)]\tLoss: 192.748352\n",
      "Average loss: 187.72429473161188 - Average reg: 5.033098313600015\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(5):\n",
    "    epoch_loss = 0\n",
    "    epoch_reg = 0\n",
    "    # one epoch\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)    \n",
    "        batch_size, channel, height, width = inputs.size()\n",
    "        recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "        loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                           None, latent_sample=latent_sample)        \n",
    "        # penalize change in one attribute wrt the other attributes\n",
    "        if args.attr_lamb > 0:\n",
    "            s = deepcopy(latent_dist[0].detach())\n",
    "            s = s.requires_grad_(True)\n",
    "            s_output = m(s)\n",
    "            attr_reg = 0\n",
    "            for i in range(model.latent_dim):\n",
    "                col_idx = np.arange(model.latent_dim)!=i\n",
    "                gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                                retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "                gradient_pairwise = gradients[:,col_idx]\n",
    "                attr_reg += args.attr_lamb * L1Loss(gradient_pairwise, torch.zeros_like(gradient_pairwise))\n",
    "        loss += attr_reg\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_reg += attr_reg.item()      \n",
    "        print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(labels), len(train_loader.dataset),\n",
    "                   100. * batch_idx / len(train_loader), loss.data.item()), end='')        \n",
    "    mean_epoch_loss = epoch_loss / len(train_loader)\n",
    "    mean_epoch_reg = epoch_reg / len(train_loader)\n",
    "    print('\\nAverage loss: {} - Average reg: {}'.format(mean_epoch_loss, mean_epoch_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.76879495649194 0.04623346317059068\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "epoch_loss = 0\n",
    "epoch_reg = 0\n",
    "for batch_idx, (inputs, labels) in enumerate(train_loader):     \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)    \n",
    "    batch_size, channel, height, width = inputs.size()\n",
    "    recon_batch, latent_dist, latent_sample = model(inputs)\n",
    "\n",
    "    loss = loss_f(inputs, recon_batch, latent_dist, model.training,\n",
    "                       None, latent_sample=latent_sample)          \n",
    "    # penalize change in one attribute wrt the other attributes\n",
    "    s = deepcopy(latent_dist[0].detach())\n",
    "    s = s.requires_grad_(True)\n",
    "    s_output = m(s)\n",
    "    attr_reg = 0\n",
    "    for i in range(model.latent_dim):\n",
    "        col_idx = np.arange(model.latent_dim)!=i\n",
    "        gradients = torch.autograd.grad(s_output[:,i], s, grad_outputs=torch.ones_like(s_output[:,i]), \n",
    "                                        retain_graph=True, create_graph=True, only_inputs=True)[0]\n",
    "        gradient_pairwise = gradients[:,col_idx]\n",
    "        attr_reg += L1Loss(gradient_pairwise, torch.zeros_like(gradient_pairwise))\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_reg += attr_reg.item()  \n",
    "print(epoch_loss/len(train_loader), epoch_reg/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
