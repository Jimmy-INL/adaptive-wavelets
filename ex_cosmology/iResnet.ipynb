{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "import torchvision.utils as vutils\n",
    "import models\n",
    "from visualize import *\n",
    "from data import *\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "from functools import partial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_path = './cosmo'\n",
    "# invertible nn\n",
    "sys.path.append('../../invertible-resnet')\n",
    "sys.path.append('../../invertible-resnet/models')\n",
    "from conv_iResNet import conv_iResNet as iResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "img_size = 256\n",
    "class_num = 1\n",
    "\n",
    "# cosmo dataset\n",
    "transformer = transforms.Compose([ToTensor()])\n",
    "mnu_dataset = MassMapsDataset(opj(data_path, 'cosmological_parameters.txt'),  \n",
    "                              opj(data_path, 'z1_256'),\n",
    "                              transform=transformer)\n",
    "\n",
    "# dataloader\n",
    "data_loader = torch.utils.data.DataLoader(mnu_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# load model\n",
    "model = models.load_model(model_name='resnet18', device=device, inplace=False, data_path=data_path).to(device)\n",
    "model = model.eval()\n",
    "# freeze layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test im\n",
    "batches = []\n",
    "seen = 0\n",
    "for data in data_loader:\n",
    "    inputs, params = data['image'], data['params']\n",
    "    batches.append(inputs)\n",
    "    seen += inputs.size(0)\n",
    "    if seen >= 10:\n",
    "        break\n",
    "init_batch = torch.cat(batches)\n",
    "\n",
    "# output\n",
    "with torch.no_grad():\n",
    "    model = model.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InvertibleResnetConv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-39a2929ec5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvertibleResnetConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_num_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'InvertibleResnetConv' is not defined"
     ]
    }
   ],
   "source": [
    "t = InvertibleResnetConv(1,32, list_num_blocks=(2,2,2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-34fc7a11cb38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertibleResnetConv(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim = 32, magnitude=0.7, reverse_iterations=10, bias=False, n_power_iterations=10):\n",
    "        super(InvertibleResnetConv, self).__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.reverse_iterations = reverse_iterations        \n",
    "        self.nets = nn.ModuleList()        \n",
    "        \n",
    "        l = nn.ModuleList()\n",
    "        net = nn.Sequential(spectral_norm(nn.Conv2d(dim, hidden_dim, kernel_size=7, stride=2, padding=3, bias=bias),\n",
    "                                          n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                            nn.ReLU(),\n",
    "                            spectral_norm(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1, bias=bias), \n",
    "                                          n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                            nn.ReLU(),\n",
    "                           )           \n",
    "        b = block(net, reverse_iterations=reverse_iterations)       \n",
    "        \n",
    "        \n",
    "        for num_blocks in list_num_blocks:    \n",
    "            l = nn.ModuleList()\n",
    "            for i in range(0,num_blocks):\n",
    "                net = nn.Sequential(nn.ReLU(),\n",
    "                                    spectral_norm(nn.Conv2d(dim, hidden_dim, kernel_size=3, bias=bias), n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                                    nn.ReLU(),\n",
    "                                    spectral_norm(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1, bias=bias), n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                                    nn.ReLU(),\n",
    "                                    spectral_norm(nn.Conv2d(hidden_dim, dim, kernel_size=3, bias=bias), n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                                   )        \n",
    "                b = block(net, reverse_iterations=reverse_iterations)            \n",
    "                l.append(ActNorm(dim))\n",
    "                l.append(b) \n",
    "            dim *= 2            \n",
    "            self.nets.append(nn.Sequential(*l))\n",
    "        \n",
    "    def forward(self, x_list, reverse=False, reverse_iterations=None):\n",
    "        if reverse:\n",
    "            for i, net in enumerate(self.nets[::-1]):\n",
    "                if i == 0:\n",
    "                    x = x_list[len(self.nets)-1-i]\n",
    "                else:\n",
    "                    x = torch.cat([x, x_list[len(self.nets)-1-i]], dim=1)                \n",
    "                for module in net[::-1]:\n",
    "                    x = apply_module_reverse(module, x, reverse_iterations)\n",
    "            return x\n",
    "        else:\n",
    "            y_list = []\n",
    "            x = x_list\n",
    "            \n",
    "            for i, net in enumerate(self.nets):                            \n",
    "                x = net(x)  \n",
    "                if i < len(self.nets)-1: \n",
    "                    y_list.append(x[:,x.shape[1]//2:])\n",
    "                    x = x[:,:x.shape[1]//2] \n",
    "            y_list.append(x)\n",
    "            return y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_module_reverse(module, x, reverse_iterations=None):\n",
    "    if 'block' in str(module.__class__):\n",
    "        return module(x, reverse=True, reverse_iterations=reverse_iterations)\n",
    "    else:\n",
    "        return module(x, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1\n",
    "hidden_dim = 32\n",
    "bias = False\n",
    "n_power_iterations = 10\n",
    "magnitude = 0.7\n",
    "net = nn.Sequential(nn.ReLU(),\n",
    "                    spectral_norm(nn.Conv2d(dim, hidden_dim, 3, padding=1, bias=bias), n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                    nn.ReLU(),\n",
    "                    spectral_norm(nn.Conv2d(hidden_dim, hidden_dim, 1, bias=bias), n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                    nn.ReLU(),\n",
    "                    spectral_norm(nn.Conv2d(hidden_dim, dim, 3, padding=1, bias=bias), n_power_iterations=n_power_iterations, magnitude=magnitude),\n",
    "                   )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 128, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = SqueezeLayer()\n",
    "a(init_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 256, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, net, reverse_iterations=40):\n",
    "        super(block, self).__init__()\n",
    "        self.reverse_iterations = reverse_iterations\n",
    "        self.net = net # residual neural network \n",
    "        self.normalize(self.net) # normalize weight\n",
    "    def normalize(self, net):\n",
    "        for n in net.modules():\n",
    "            for k,hook in n._forward_pre_hooks.items():\n",
    "                if isinstance(hook,SpectralNorm):\n",
    "                    hook(n, None)\n",
    "    def calcG(self, x):\n",
    "        return self.net(x)\n",
    "    def forward(self, x, reverse=False, reverse_iterations=None):\n",
    "        if reverse:\n",
    "            y = x\n",
    "            for count in range(reverse_iterations if reverse_iterations else self.reverse_iterations):\n",
    "                x = y - self.calcG(x)\n",
    "            return x\n",
    "        else:            \n",
    "            y = self.calcG(x) + x\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.loc = nn.Parameter(torch.zeros(1, in_channel, 1, 1))\n",
    "        self.scale = nn.Parameter(torch.ones(1, in_channel, 1, 1))\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, input):\n",
    "        with torch.no_grad():\n",
    "            if len(input.shape) == 2: # linear\n",
    "                flatten = input.permute(1, 0).contiguous().view(input.shape[1], -1)\n",
    "                mean = (\n",
    "                    flatten.mean(1)\n",
    "                    .unsqueeze(1)\n",
    "                    .permute(1, 0,)\n",
    "                )\n",
    "                std = (\n",
    "                    flatten.std(1)\n",
    "                    .unsqueeze(1)\n",
    "                    .permute(1, 0)\n",
    "                )\n",
    "                self.loc.data.copy_(-mean.view_as(self.loc))\n",
    "                self.scale.data.copy_(1 / (std.view_as(self.scale) + 1e-6))\n",
    "            elif len(input.shape) == 4: # conv\n",
    "                flatten = input.permute(1, 0, 2, 3).contiguous().view(input.shape[1], -1)\n",
    "                mean = (\n",
    "                    flatten.mean(1)\n",
    "                    .unsqueeze(1)\n",
    "                    .unsqueeze(2)\n",
    "                    .unsqueeze(3)\n",
    "                    .permute(1, 0, 2, 3)\n",
    "                )\n",
    "                std = (\n",
    "                    flatten.std(1)\n",
    "                    .unsqueeze(1)\n",
    "                    .unsqueeze(2)\n",
    "                    .unsqueeze(3)\n",
    "                    .permute(1, 0, 2, 3)\n",
    "                )\n",
    "\n",
    "                self.loc.data.copy_(-mean)\n",
    "                self.scale.data.copy_(1 / (std + 1e-6))\n",
    "            else:\n",
    "                raise 'Input shape not supported {}'.format(input.shape)\n",
    "    \n",
    "    def forward(self, input, reverse=False):\n",
    "        \n",
    "        scale = self.scale if len(input.shape) == 4 else self.scale.view(1, -1)\n",
    "        loc = self.loc if len(input.shape) == 4 else self.loc.view(1, -1)\n",
    "        \n",
    "        if reverse:\n",
    "            return input / scale - loc\n",
    "\n",
    "        if not self.initialized:\n",
    "            self.initialize(input)\n",
    "            self.initialized = True\n",
    "        \n",
    "        return scale * (input + loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_norm(module, name='weight', n_power_iterations=1, magnitude=1.0, eps=1e-12):\n",
    "    r\"\"\"Applies spectral normalization to a parameter in the given module.\n",
    "    .. math::\n",
    "         \\mathbf{W} = \\dfrac{\\mathbf{W}}{\\sigma(\\mathbf{W})} \\\\\n",
    "         \\sigma(\\mathbf{W}) = \\max_{\\mathbf{h}: \\mathbf{h} \\ne 0} \\dfrac{\\|\\mathbf{W} \\mathbf{h}\\|_2}{\\|\\mathbf{h}\\|_2}\n",
    "    Spectral normalization stabilizes the training of discriminators (critics)\n",
    "    in Generaive Adversarial Networks (GANs) by rescaling the weight tensor\n",
    "    with spectral norm :math:`\\sigma` of the weight matrix calculated using\n",
    "    power iteration method. If the dimension of the weight tensor is greater\n",
    "    than 2, it is reshaped to 2D in power iteration method to get spectral\n",
    "    norm. This is implemented via a hook that calculates spectral norm and\n",
    "    rescales weight before every :meth:`~Module.forward` call.\n",
    "    See `Spectral Normalization for Generative Adversarial Networks`_ .\n",
    "    .. _`Spectral Normalization for Generative Adversarial Networks`: https://arxiv.org/abs/1802.05957\n",
    "    Args:\n",
    "        module (nn.Module): containing module\n",
    "        name (str, optional): name of weight parameter\n",
    "        n_power_iterations (int, optional): number of power iterations to\n",
    "            calculate spectal norm\n",
    "        eps (float, optional): epsilon for numerical stability in\n",
    "            calculating norms\n",
    "        dim (int, optional): dimension corresponding to number of outputs,\n",
    "            the default is 0, except for modules that are instances of\n",
    "            ConvTranspose1/2/3d, when it is 1\n",
    "    Returns:\n",
    "        The original module with the spectal norm hook\n",
    "    Example::\n",
    "        >>> m = spectral_norm(nn.Linear(20, 40))\n",
    "        Linear (20 -> 40)\n",
    "        >>> m.weight_u.size()\n",
    "        torch.Size([20])\n",
    "    \"\"\"    \n",
    "    SpectralNorm.apply(module, name, n_power_iterations, magnitude, eps)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = spectral_norm(nn.Linear(20, 40))\n",
    "mod = nn.Linear(20, 40)\n",
    "# mod = nn.Conv2d(10,10,5)\n",
    "weight = mod._parameters['weight']\n",
    "mod.forward_function = lambda inp,weight=weight: F.linear(inp, weight)\n",
    "mod.iteration_function = lambda inp,weight=weight: F.linear(F.linear(inp, weight), weight.transpose(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    shape = (1,weight.shape[1])\n",
    "    u = torch.randn(shape).to(weight.device)  \n",
    "    \n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        u = mod.iteration_function(u, weight=weight)\n",
    "    u = u.clone()\n",
    "    sv = torch.sqrt((mod.forward_function(u, weight=weight)**2).sum()) / torch.sqrt((u**2).sum())\n",
    "    sigma = F.relu(sv / 1.0 - 1.0) + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.svd(weight.data.numpy())[1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNorm(object):\n",
    "    # Invariant before and after each forward call:\n",
    "    #   u = normalize(W @ v)\n",
    "    # NB: At initialization, this invariant is not enforced\n",
    "\n",
    "    _version = 2\n",
    "    # At version 2:\n",
    "    #   used Gouk 2018 method.\n",
    "    #   will only normalize if largest singular value > magnitude    \n",
    "\n",
    "    def __init__(self, name='weight', n_power_iterations=1, magnitude=1.0, eps=1e-12):\n",
    "        self.name = name\n",
    "        self.magnitude = magnitude\n",
    "        if n_power_iterations <= 0:\n",
    "            raise ValueError('Expected n_power_iterations to be positive, but '\n",
    "                             'got n_power_iterations={}'.format(n_power_iterations))\n",
    "        self.n_power_iterations = n_power_iterations\n",
    "        self.eps = eps\n",
    "    def l2norm(self, t):\n",
    "        return torch.sqrt((t ** 2).sum())\n",
    "    def compute_weight(self, module, do_power_iteration, num_iter=0):      \n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        u = getattr(module, self.name + '_u')\n",
    "        \n",
    "        if do_power_iteration:\n",
    "            with torch.no_grad():\n",
    "                for _ in range(max(self.n_power_iterations, num_iter)):\n",
    "                    u = module.iteration_function(u, weight=weight)\n",
    "                if self.n_power_iterations > 0:\n",
    "                    # See above on why we need to clone\n",
    "                    u = u.clone()\n",
    "                sv = self.l2norm(module.forward_function(u, weight=weight)) / self.l2norm(u)      \n",
    "                sigma = F.relu(sv / self.magnitude - 1.0) + 1.0\n",
    "                module.sigma = sigma\n",
    "        else:\n",
    "            sigma = module.sigma\n",
    "        \n",
    "        return weight / sigma\n",
    "\n",
    "    def remove(self, module):\n",
    "        with torch.no_grad():\n",
    "            weight = self.compute_weight(module, do_power_iteration=False)\n",
    "        delattr(module, self.name)\n",
    "        delattr(module, self.name + '_u')\n",
    "        delattr(module, self.name + '_sigma')\n",
    "        delattr(module, self.name + '_orig')\n",
    "        module.register_parameter(self.name, torch.nn.Parameter(weight.detach()))\n",
    "\n",
    "    def __call__(self, module, inputs, n_power_iterations=0):\n",
    "        setattr(module, self.name, self.compute_weight(module, do_power_iteration=module.training, num_iter=n_power_iterations))\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(module, name, n_power_iterations, magnitude, eps):\n",
    "        for k, hook in module._forward_pre_hooks.items():\n",
    "            if isinstance(hook, SpectralNorm) and hook.name == name:\n",
    "                raise RuntimeError(\"Cannot register two spectral_norm hooks on \"\n",
    "                                   \"the same parameter {}\".format(name))\n",
    "\n",
    "        fn = SpectralNorm(name, n_power_iterations, magnitude, eps)\n",
    "        weight = module._parameters[name]\n",
    "        \n",
    "        functions_dict = {torch.nn.Conv1d : (F.conv1d, F.conv_transpose1d),\n",
    "             torch.nn.Conv2d : (F.conv2d, F.conv_transpose2d),\n",
    "             torch.nn.Conv3d : (F.conv3d, F.conv_transpose3d),\n",
    "             torch.nn.ConvTranspose1d : (F.conv_transpose1d, F.conv1d),\n",
    "             torch.nn.ConvTranspose2d : (F.conv_transpose2d, F.conv2d),\n",
    "             torch.nn.ConvTranspose3d : (F.conv_transpose3d, F.conv3d),            \n",
    "            }\n",
    "        \n",
    "        if isinstance(module, torch.nn.Linear):  \n",
    "            module.forward_function = lambda inp,weight=weight: F.linear(inp, weight)\n",
    "            module.iteration_function = lambda inp,weight=weight: F.linear(F.linear(inp, weight), weight.transpose(1,0))\n",
    "        elif isinstance(module, (torch.nn.ConvTranspose1d,\n",
    "                               torch.nn.ConvTranspose2d,\n",
    "                               torch.nn.ConvTranspose3d,\n",
    "                               torch.nn.Conv1d,\n",
    "                               torch.nn.Conv2d,\n",
    "                               torch.nn.Conv3d,)):\n",
    "            k = weight.shape[2:]\n",
    "            s = module.stride\n",
    "            g = module.groups\n",
    "            d = module.dilation\n",
    "            p = module.padding\n",
    "            functions = functions_dict[module.__class__ ]\n",
    "            module.forward_function = lambda inp,weight=weight,s=s,g=g,d=d,p=p: functions[0](inp, weight, stride=s, padding=p, dilation=d, groups=g)            \n",
    "            module.iteration_function = lambda inp,weight=weight,s=s,g=g,d=d,p=p: functions[1](functions[0](inp, weight, stride=s, padding=p, dilation=d, groups=g), \n",
    "                                                                                             weight, stride=s, padding=p, dilation=d, groups=g)\n",
    "            \n",
    "            \n",
    "        with torch.no_grad():\n",
    "            shape = (1,weight.shape[1])\n",
    "            for i in range(0,len(weight.shape)-2):\n",
    "                shape += (max(k[i]*d[i],1),)\n",
    "            u = torch.randn(shape).to(weight.device)\n",
    "            \n",
    "\n",
    "        delattr(module, fn.name)\n",
    "        module.register_parameter(fn.name + \"_orig\", weight)\n",
    "        # We still need to assign weight back as fn.name because all sorts of\n",
    "        # things may assume that it exists, e.g., when initializing weights.\n",
    "        # However, we can't directly assign as it could be an nn.Parameter and\n",
    "        # gets added as a parameter. Instead, we register weight.data as a plain\n",
    "        # attribute.\n",
    "        setattr(module, fn.name, weight.data)\n",
    "        module.register_buffer(fn.name + \"_u\", u)\n",
    "        sigma = torch.tensor(1).to(weight.device)\n",
    "        module.register_buffer(fn.name + \"_sigma\", sigma)\n",
    "\n",
    "        module.register_forward_pre_hook(fn)\n",
    "\n",
    "        module._register_state_dict_hook(SpectralNormStateDictHook(fn))\n",
    "        module._register_load_state_dict_pre_hook(SpectralNormLoadStateDictPreHook(fn))\n",
    "        return fn\n",
    "    \n",
    "    \n",
    "class SpectralNormStateDictHook(object):\n",
    "    # See docstring of SpectralNorm._version on the changes to spectral_norm.\n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "\n",
    "    def __call__(self, module, state_dict, prefix, local_metadata):\n",
    "        pass    \n",
    "\n",
    "# This is a top level class because Py2 pickle doesn't like inner class nor an\n",
    "# instancemethod.\n",
    "class SpectralNormLoadStateDictPreHook(object):\n",
    "    # See docstring of SpectralNorm._version on the changes to spectral_norm.\n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "\n",
    "    # For state_dict with version None, (assuming that it has gone through at\n",
    "    # least one training forward), we have\n",
    "    #\n",
    "    #    u = normalize(W_orig @ v)\n",
    "    #    W = W_orig / sigma, where sigma = u @ W_orig @ v\n",
    "    #\n",
    "    # To compute `v`, we solve `W_orig @ x = u`, and let\n",
    "    #    v = x / (u @ W_orig @ x) * (W / W_orig).\n",
    "    def __call__(self, state_dict, prefix, local_metadata, strict,\n",
    "                 missing_keys, unexpected_keys, error_msgs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = InvertibleResnetConv(dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model_t = iResNet(nBlocks=[4,4,4], nStrides=[1,2,2],\n",
    "                nChannels=[1,64,256], nClasses=10,\n",
    "                init_ds=2,\n",
    "                inj_pad=0,\n",
    "                in_shape=init_batch.shape[1:],\n",
    "                coeff=.9,\n",
    "                numTraceSamples=1,\n",
    "                numSeriesTerms=1,\n",
    "                n_power_iter=5,\n",
    "                density_estimation=False,\n",
    "                actnorm=True,\n",
    "                learn_prior=True,\n",
    "                nonlin=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_iResNet(nn.Module):\n",
    "    def __init__(self, in_shape, nBlocks, nStrides, nChannels, init_ds=2, inj_pad=0,\n",
    "                 coeff=.9, density_estimation=False, nClasses=None,\n",
    "                 numTraceSamples=1, numSeriesTerms=1,\n",
    "                 n_power_iter=5,\n",
    "                 block=conv_iresnet_block,\n",
    "                 actnorm=True, learn_prior=True,\n",
    "                 nonlin=\"relu\"):\n",
    "        super(conv_iResNet, self).__init__()\n",
    "        assert len(nBlocks) == len(nStrides) == len(nChannels)\n",
    "        assert init_ds in (1, 2), \"can only squeeze by 2\"\n",
    "        self.init_ds = init_ds\n",
    "        self.ipad = inj_pad\n",
    "        self.nBlocks = nBlocks\n",
    "        self.density_estimation = density_estimation\n",
    "        self.nClasses = nClasses\n",
    "        # parameters for trace estimation\n",
    "        self.numTraceSamples = numTraceSamples if density_estimation else 0\n",
    "        self.numSeriesTerms = numSeriesTerms if density_estimation else 0\n",
    "        self.n_power_iter = n_power_iter\n",
    "\n",
    "        print('')\n",
    "        print(' == Building iResNet %d == ' % (sum(nBlocks) * 3 + 1))\n",
    "        self.init_squeeze = Squeeze(self.init_ds)\n",
    "        self.inj_pad = injective_pad(inj_pad)\n",
    "        if self.init_ds == 2:\n",
    "           in_shape = downsample_shape(in_shape)\n",
    "        in_shape = (in_shape[0] + inj_pad, in_shape[1], in_shape[2])  # adjust channels\n",
    "\n",
    "        self.stack, self.in_shapes, self.final_shape = self._make_stack(nChannels, nBlocks, nStrides,\n",
    "                                                                        in_shape, coeff, block,\n",
    "                                                                        actnorm, n_power_iter, nonlin)\n",
    "\n",
    "        # make prior distribution\n",
    "        self._make_prior(learn_prior)\n",
    "        # make classifier\n",
    "        self._make_classifier(self.final_shape, nClasses)\n",
    "        assert (nClasses is not None or density_estimation), \"Must be either classifier or density estimator\"\n",
    "\n",
    "    def _make_prior(self, learn_prior):\n",
    "        dim = np.prod(self.in_shapes[0])\n",
    "        self.prior_mu = nn.Parameter(torch.zeros((dim,)).float(), requires_grad=learn_prior)\n",
    "        self.prior_logstd = nn.Parameter(torch.zeros((dim,)).float(), requires_grad=learn_prior)\n",
    "\n",
    "    def _make_classifier(self, final_shape, nClasses):\n",
    "        if nClasses is None:\n",
    "            self.logits = None\n",
    "        else:\n",
    "            self.bn1 = nn.BatchNorm2d(final_shape[0], momentum=0.9)\n",
    "            self.logits = nn.Linear(final_shape[0], nClasses)\n",
    "\n",
    "    def classifier(self, z):\n",
    "        out = F.relu(self.bn1(z))\n",
    "        out = F.avg_pool2d(out, out.size(2))\n",
    "        out = out.view(out.size(0), out.size(1))\n",
    "        return self.logits(out)\n",
    "\n",
    "    def prior(self):\n",
    "        return distributions.Normal(self.prior_mu, torch.exp(self.prior_logstd))\n",
    "\n",
    "    def logpz(self, z):\n",
    "        return self.prior().log_prob(z.view(z.size(0), -1)).sum(dim=1)\n",
    "\n",
    "    def _make_stack(self, nChannels, nBlocks, nStrides, in_shape, coeff, block,\n",
    "                    actnorm, n_power_iter, nonlin):\n",
    "        \"\"\" Create stack of iresnet blocks \"\"\"\n",
    "        block_list = nn.ModuleList()\n",
    "        in_shapes = []\n",
    "        for i, (int_dim, stride, blocks) in enumerate(zip(nChannels, nStrides, nBlocks)):\n",
    "            for j in range(blocks):\n",
    "                in_shapes.append(in_shape)\n",
    "                block_list.append(block(in_shape, int_dim,\n",
    "                                        numTraceSamples=self.numTraceSamples,\n",
    "                                        numSeriesTerms=self.numSeriesTerms,\n",
    "                                        stride=(stride if j == 0 else 1),  # use stride if first layer in block else 1\n",
    "                                        input_nonlin=(i + j > 0),  # add nonlinearity to input for all but fist layer\n",
    "                                        coeff=coeff,\n",
    "                                        actnorm=actnorm,\n",
    "                                        n_power_iter=n_power_iter,\n",
    "                                        nonlin=nonlin))\n",
    "                if stride == 2 and j == 0:\n",
    "                    in_shape = downsample_shape(in_shape)\n",
    "\n",
    "        return block_list, in_shapes, in_shape\n",
    "\n",
    "    def get_in_shapes(self):\n",
    "        return self.in_shapes\n",
    "    \n",
    "    def inspect_singular_values(self):\n",
    "        i = 0\n",
    "        j = 0\n",
    "        params = [v for v in self.state_dict().keys()\n",
    "                  if \"bottleneck\" in v and \"weight_orig\" in v\n",
    "                  and not \"weight_u\" in v\n",
    "                  and not \"bn1\" in v\n",
    "                  and not \"linear\" in v]\n",
    "        print(len(params))\n",
    "        print(len(self.in_shapes))\n",
    "        svs = [] \n",
    "        for param in params:\n",
    "          input_shape = tuple(self.in_shapes[j])\n",
    "          # get unscaled parameters from state dict\n",
    "          convKernel_unscaled = self.state_dict()[param].cpu().numpy()\n",
    "          # get scaling by spectral norm\n",
    "          sigma = self.state_dict()[param[:-5] + '_sigma'].cpu().numpy()\n",
    "          convKernel = convKernel_unscaled / sigma\n",
    "          # compute singular values\n",
    "          input_shape = input_shape[1:]\n",
    "          fft_coeff = np.fft.fft2(convKernel, input_shape, axes=[2, 3])\n",
    "          t_fft_coeff = np.transpose(fft_coeff)\n",
    "          D = np.linalg.svd(t_fft_coeff, compute_uv=False, full_matrices=False)\n",
    "          Dflat = np.sort(D.flatten())[::-1] \n",
    "          print(\"Layer \"+str(j)+\" Singular Value \"+str(Dflat[0]))\n",
    "          svs.append(Dflat[0])\n",
    "          if i == 2:\n",
    "            i = 0\n",
    "            j+= 1\n",
    "          else:\n",
    "            i+=1\n",
    "        return svs\n",
    "\n",
    "    def forward(self, x, ignore_logdet=False):\n",
    "        \"\"\" iresnet forward \"\"\"\n",
    "        if self.init_ds == 2:\n",
    "            x = self.init_squeeze.forward(x)\n",
    "\n",
    "        if self.ipad != 0:\n",
    "            x = self.inj_pad.forward(x)\n",
    "\n",
    "        z = x\n",
    "        traces = []\n",
    "        for block in self.stack:\n",
    "            z, trace = block(z, ignore_logdet=ignore_logdet)\n",
    "            traces.append(trace)\n",
    "\n",
    "        # no classification head\n",
    "        if self.density_estimation:\n",
    "            # add logdets\n",
    "            tmp_trace = torch.zeros_like(traces[0])\n",
    "            for k in range(len(traces)):\n",
    "                tmp_trace += traces[k]\n",
    "\n",
    "            logpz = self.logpz(z)\n",
    "            return z, logpz, tmp_trace\n",
    "\n",
    "        # classification head\n",
    "        else:\n",
    "            logits = self.classifier(z)\n",
    "            return logits, z\n",
    "\n",
    "    def inverse(self, z, max_iter=10):\n",
    "        \"\"\" iresnet inverse \"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = z\n",
    "            for i in range(len(self.stack)):\n",
    "                x = self.stack[-1 - i].inverse(x, maxIter=max_iter)\n",
    "\n",
    "            if self.ipad != 0:\n",
    "                x = self.inj_pad.inverse(x)\n",
    "\n",
    "            if self.init_ds == 2:\n",
    "                x = self.init_squeeze.inverse(x)\n",
    "        return x\n",
    "\n",
    "    def sample(self, batch_size, max_iter=10):\n",
    "        \"\"\"sample from prior and invert\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # only send batch_size to prior, prior has final_shape as attribute\n",
    "            samples = self.prior().rsample((batch_size,))\n",
    "            samples = samples.view((batch_size,) + self.final_shape)\n",
    "            return self.inverse(samples, max_iter=max_iter)\n",
    "\n",
    "    def set_num_terms(self, n_terms):\n",
    "        for block in self.stack:\n",
    "            for layer in block.stack:\n",
    "                layer.numSeriesTerms = n_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initializing actnorm parameters...\")\n",
    "with torch.no_grad():\n",
    "    model_t(init_batch, ignore_logdet=True)\n",
    "print(\"initialized\")\n",
    "\n",
    "model_t = model_t.to(device)\n",
    "optimizer = optim.Adam(model_t.parameters(), lr=.1, weight_decay=5e-4)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(1, 1+num_epochs):\n",
    "    start_time = time.time()\n",
    "    train(args, model, optimizer, epoch, trainloader, trainset, viz, use_cuda, train_log)\n",
    "    epoch_time = time.time() - start_time\n",
    "    elapsed_time += epoch_time\n",
    "    print('| Elapsed time : %d:%02d:%02d' % (get_hms(elapsed_time)))\n",
    "\n",
    "print('Testing model')\n",
    "test_log = open(os.path.join(args.save_dir, \"test_log.txt\"), 'w')\n",
    "test_objective = test(test_objective, args, model, epoch, testloader, viz, use_cuda, test_log)\n",
    "print('* Test results : objective = %.2f%%' % (test_objective))\n",
    "with open(os.path.join(args.save_dir, 'final.txt'), 'w') as f:\n",
    "    f.write(str(test_objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, optimizer, epoch, trainloader, trainset, viz, use_cuda, train_log):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # update lr for this epoch (for classification only)\n",
    "    if not args.densityEstimation:\n",
    "        lr = learning_rate(args.lr, epoch)\n",
    "        update_lr(optimizer, lr)\n",
    "    else:\n",
    "        lr = args.lr\n",
    "\n",
    "    params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    print('|  Number of Trainable Parameters: ' + str(params))\n",
    "    print('\\n=> Training Epoch #%d, LR=%.4f' % (epoch, lr))\n",
    "          \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        cur_iter = (epoch - 1) * len(trainloader) + batch_idx\n",
    "        # if first epoch use warmup\n",
    "        if epoch - 1 <= args.warmup_epochs:\n",
    "            this_lr = args.lr * float(cur_iter) / (args.warmup_epochs * len(trainloader))\n",
    "            update_lr(optimizer, this_lr)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()  # GPU settings\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs, targets = Variable(inputs, requires_grad=True), Variable(targets)\n",
    "        \n",
    "\n",
    "        if args.densityEstimation: # density estimation\n",
    "            _, logpz, trace = model(inputs)  # Forward Propagation\n",
    "            # compute loss\n",
    "            logpx = logpz + trace\n",
    "            loss = bits_per_dim(logpx, inputs).mean()\n",
    "        else: # classification\n",
    "            out, _ = model(inputs)\n",
    "            loss = criterion(out, targets) # Loss\n",
    "        \n",
    "        # logging for sigmas. NOTE: needs to be done before backward-call\n",
    "        if args.densityEstimation and args.log_verbose:\n",
    "            if batch_idx % args.log_every == 0:\n",
    "                sigmas = []\n",
    "                for k in model.state_dict().keys():\n",
    "                    if 'bottleneck' and 'weight_orig' in k:               \n",
    "                        sigma = model.state_dict()[k[:-5] + '_sigma']\n",
    "                        sigmas.append(sigma.item())\n",
    "                sigmas = np.array(sigmas)\n",
    "                line_plot(viz, \"sigma all layers\", cur_iter, sigmas)\n",
    "                \n",
    "        loss.backward()  # Backward Propagation\n",
    "        optimizer.step()  # Optimizer update\n",
    "                \n",
    "        if args.densityEstimation: # logging for density estimation\n",
    "            if batch_idx % args.log_every == 0:\n",
    "                mean_trace = trace.mean().item()\n",
    "                mean_logpz = logpz.mean().item()\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\t%% bits/dim: %.3f Trace: %.3f  logp(z) %.3f'\n",
    "                                 % (epoch, args.epochs, batch_idx+1,\n",
    "                                    (len(trainset)//args.batch)+1, loss,  mean_trace, mean_logpz))\n",
    "                sys.stdout.flush()\n",
    "                line_plot(viz, \"bits/dim\", cur_iter, loss.item())\n",
    "                line_plot(viz, \"logp(z)\", cur_iter, mean_logpz)\n",
    "                line_plot(viz, \"log|df/dz|\", cur_iter, mean_trace)\n",
    "                # file logging\n",
    "                log_dict = {\"iter\": cur_iter, \"loss\": loss.item(), \"logpz\": mean_logpz, \"logdet\": mean_trace, \"epoch\": epoch}\n",
    "                train_log.write(\"{}\\n\".format(json.dumps(log_dict)))\n",
    "                train_log.flush()\n",
    "\n",
    "                if args.log_verbose:\n",
    "                    # grad_norm_2 = sum((p.grad.norm()**2).item() for p in model.parameters() if p.grad is not None)\n",
    "                    grad_norm_inf = max(p.grad.data.abs().max().item() for p in model.parameters() if p.grad is not None)\n",
    "                    # line_plot(viz, \"grad_norm_2\", cur_iter, grad_norm_2)\n",
    "                    line_plot(viz, \"grad_norm_inf\", cur_iter, grad_norm_inf)\n",
    "                    # log actnorm scaling\n",
    "                    if not args.noActnorm:\n",
    "                        actnorm_scales = []\n",
    "                        actnorm_scales_min = []\n",
    "                        actnorm_l2 = []\n",
    "                        for k in model.state_dict().keys():\n",
    "                            if 'actnorm' and '_log_scale' in k:\n",
    "                                scale = torch.max(model.state_dict()[k])\n",
    "                                scale_min = torch.min(model.state_dict()[k])\n",
    "                                l2 = torch.norm(model.state_dict()[k])\n",
    "                                actnorm_scales.append(scale.item())\n",
    "                                actnorm_scales_min.append(scale_min.item())\n",
    "                                actnorm_l2.append(l2.item())\n",
    "                        actnorm_scales = np.array(actnorm_scales)\n",
    "                        actnorm_scales_min = np.array(actnorm_scales_min)\n",
    "                        actnorm_l2 = np.array(actnorm_l2)\n",
    "                        line_plot(viz, \"max actnorm scale per layer\", cur_iter, actnorm_scales)\n",
    "                        line_plot(viz, \"min actnorm scale per layer\", cur_iter, actnorm_scales_min)\n",
    "                        line_plot(viz, \"l2 norm of actnorm scale per layer\", cur_iter, actnorm_l2)  \n",
    "                    # learned prior logging\n",
    "                    if not args.fixedPrior:\n",
    "                        prior_scales_max = torch.max(model.state_dict()['module.prior_logstd'])\n",
    "                        prior_scales_min = torch.min(model.state_dict()['module.prior_logstd'])\n",
    "                        line_plot(viz, \"max prior scale\", cur_iter, prior_scales_max.item())\n",
    "                        line_plot(viz, \"min prior scale\", cur_iter, prior_scales_min.item())  \n",
    "\n",
    "        else: # logging for classification\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()    \n",
    "            if batch_idx % 1 == 0:\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f'\n",
    "                                 % (epoch, args.epochs, batch_idx+1,\n",
    "                                    (len(trainset)//args.batch)+1, loss.data.item(),\n",
    "                                    100.*correct.type(torch.FloatTensor)/float(total)))\n",
    "                sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(init, epoch):\n",
    "    optim_factor = 0\n",
    "    if epoch > 160:\n",
    "        optim_factor = 3\n",
    "    elif epoch > 120:\n",
    "        optim_factor = 2\n",
    "    elif epoch > 60:\n",
    "        optim_factor = 1\n",
    "    return init*math.pow(0.2, optim_factor)\n",
    "\n",
    "def zero_grad(model):\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            p.grad.detach_()\n",
    "            p.grad.zero_()\n",
    "            \n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python CIFAR_main.py --nBlocks 16 16 16 --nStrides 1 2 2 --nChannels 512 512 512 --coeff 0.9 -densityEstimation -multiScale --lr 0.003 --weight_decay 0. \n",
    "--numSeriesTerms 5 --dataset cifar10 --batch 128 --warmup_epochs 1 --save_dir ./results/dens_est_cifar --vis_server your.server.local --vis_port your_port_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "img_size = 256\n",
    "class_num = 1\n",
    "\n",
    "# cosmo dataset\n",
    "transformer = transforms.Compose([ToTensor()])\n",
    "mnu_dataset = MassMapsDataset(opj(data_path, 'cosmological_parameters.txt'),  \n",
    "                              opj(data_path, 'z1_256'),\n",
    "                              transform=transformer)\n",
    "\n",
    "# dataloader\n",
    "data_loader = torch.utils.data.DataLoader(mnu_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# load model\n",
    "model = models.load_model(model_name='resnet18', device=device, inplace=False, data_path=data_path).to(device)\n",
    "model = model.eval()\n",
    "# freeze layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transform, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=2, padding=3, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Transform_i(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transform_i, self).__init__()\n",
    "        self.convt1 = nn.ConvTranspose2d(64, 1, kernel_size=7, stride=2, padding=3, output_padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convt1(x)\n",
    "    \n",
    "    \n",
    "def gradient_pen(gen_frames, alpha=2):\n",
    "\n",
    "    def gradient(x):\n",
    "        # idea from tf.image.image_gradients(image)\n",
    "        # https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/image_ops_impl.py#L3441-L3512\n",
    "        # x: (b,c,h,w), float32 or float64\n",
    "        # dx, dy: (b,c,h,w)\n",
    "\n",
    "        h_x = x.size()[-2]\n",
    "        w_x = x.size()[-1]\n",
    "        # gradient step=1\n",
    "        left = x\n",
    "        right = F.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n",
    "        top = x\n",
    "        bottom = F.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n",
    "\n",
    "        # dx, dy = torch.abs(right - left), torch.abs(bottom - top)\n",
    "        dx, dy = right - left, bottom - top \n",
    "        # dx will always have zeros in the last column, right-left\n",
    "        # dy will always have zeros in the last row,    bottom-top\n",
    "        dx[:, :, :, -1] = 0\n",
    "        dy[:, :, -1, :] = 0\n",
    "\n",
    "        return dx, dy\n",
    "    \n",
    "    # gradient\n",
    "    gen_dx, gen_dy = gradient(gen_frames)\n",
    "    \n",
    "    # condense into one tensor and avg\n",
    "    return torch.mean(gen_dx ** alpha + gen_dy ** alpha)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test im\n",
    "X = iter(data_loader).next()['image'][0:1].to(device)\n",
    "X.requires_grad = True\n",
    "\n",
    "# output\n",
    "with torch.no_grad():\n",
    "    output = model(X).flatten()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize over mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test im\n",
    "X = iter(data_loader).next()['image'][0:1].to(device)\n",
    "X.requires_grad = True\n",
    "\n",
    "# output\n",
    "with torch.no_grad():\n",
    "    output = model(X).flatten()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(nn.Module):\n",
    "    def __init__(self, img_size=256):\n",
    "        super(Mask, self).__init__()\n",
    "        self.mask = nn.Parameter(torch.ones(img_size, img_size))\n",
    "#         self.mask = nn.Parameter(torch.clamp(abs(torch.randn(img_size, img_size)), 0, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.mul(self.mask, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask\n",
    "mask = Mask().to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# l1-loss\n",
    "l1loss = nn.L1Loss()\n",
    "\n",
    "# Setup Adam optimizer\n",
    "optimizer = optim.Adam(mask.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "# Lists to keep track of progress\n",
    "losses = []\n",
    "num_epochs = 1000\n",
    "\n",
    "lamb_l1 = 5.0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    im_mask = mask(X)\n",
    "    output_ = model(im_mask).flatten()[1] \n",
    "    # loss\n",
    "    loss = -output_ + lamb_l1 * l1loss(mask.mask, torch.zeros_like(mask.mask))\n",
    "    # zero grad\n",
    "    optimizer.zero_grad()\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    # Update G\n",
    "    optimizer.step()\n",
    "    # projection\n",
    "    mask.mask.data = torch.clamp(mask.mask.data, 0, 1)\n",
    "\n",
    "    # Output training stats\n",
    "    print('\\rTrain Epoch: {}/{}'.format(epoch, num_epochs), end='')\n",
    "\n",
    "    # Save Losses for plotting later\n",
    "    losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshow(mask(X).data.cpu().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshow(X.data.cpu().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
