{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "import torchvision.utils as vutils\n",
    "import models\n",
    "from visualize import *\n",
    "from data import *\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "from functools import partial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_path = './cosmo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "img_size = 256\n",
    "class_num = 1\n",
    "\n",
    "# cosmo dataset\n",
    "transformer = transforms.Compose([ToTensor()])\n",
    "mnu_dataset = MassMapsDataset(opj(data_path, 'cosmological_parameters.txt'),  \n",
    "                              opj(data_path, 'z1_256'),\n",
    "                              transform=transformer)\n",
    "\n",
    "# dataloader\n",
    "data_loader = torch.utils.data.DataLoader(mnu_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# load model\n",
    "model = models.load_model(model_name='resnet18', device=device, inplace=False, data_path=data_path).to(device)\n",
    "model = model.eval()\n",
    "# freeze layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transform, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=2, padding=3, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Transform_i(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transform_i, self).__init__()\n",
    "        self.convt1 = nn.ConvTranspose2d(64, 1, kernel_size=7, stride=2, padding=3, output_padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convt1(x)\n",
    "    \n",
    "    \n",
    "def gradient_pen(gen_frames, alpha=2):\n",
    "\n",
    "    def gradient(x):\n",
    "        # idea from tf.image.image_gradients(image)\n",
    "        # https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/image_ops_impl.py#L3441-L3512\n",
    "        # x: (b,c,h,w), float32 or float64\n",
    "        # dx, dy: (b,c,h,w)\n",
    "\n",
    "        h_x = x.size()[-2]\n",
    "        w_x = x.size()[-1]\n",
    "        # gradient step=1\n",
    "        left = x\n",
    "        right = F.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n",
    "        top = x\n",
    "        bottom = F.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n",
    "\n",
    "        # dx, dy = torch.abs(right - left), torch.abs(bottom - top)\n",
    "        dx, dy = right - left, bottom - top \n",
    "        # dx will always have zeros in the last column, right-left\n",
    "        # dy will always have zeros in the last row,    bottom-top\n",
    "        dx[:, :, :, -1] = 0\n",
    "        dy[:, :, -1, :] = 0\n",
    "\n",
    "        return dx, dy\n",
    "    \n",
    "    # gradient\n",
    "    gen_dx, gen_dy = gradient(gen_frames)\n",
    "    \n",
    "    # condense into one tensor and avg\n",
    "    return torch.mean(gen_dx ** alpha + gen_dy ** alpha)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transforms\n",
    "t = Transform().to(device)\n",
    "transform_i = Transform_i().to(device)\n",
    "# transform_i.load_state_dict(torch.load('./models/conv_filters_pen'))\n",
    "\n",
    "ims = iter(data_loader).next()['image']\n",
    "ims = ims.to(device)\n",
    "\n",
    "# prepend transformation\n",
    "model_t = TrimModel(model, transform_i, use_residuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# l1-loss\n",
    "l1loss = nn.L1Loss()\n",
    "\n",
    "# Setup Adam optimizers\n",
    "optimizer_t = optim.Adam(t.parameters(), lr=0.0005)\n",
    "optimizer_i = optim.Adam(transform_i.parameters(), lr=0.0005)\n",
    "\n",
    "# mask\n",
    "padding = 3\n",
    "dim = padding*2+1\n",
    "mask = torch.ones(64, 64, dim, dim).to(device)\n",
    "for i in range(64):\n",
    "    mask[i,i,padding,padding] = 0\n",
    "    \n",
    "zeros = torch.zeros(64, 64, dim, dim).to(device)\n",
    "\n",
    "# conv operator for penalty\n",
    "c_t = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=padding, bias=False).to(device)\n",
    "c_i = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=padding, bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "# Lists to keep track of progress\n",
    "losses = []\n",
    "num_epochs = 2\n",
    "\n",
    "lamb = 5.0\n",
    "lamb_smth = 0.5\n",
    "lamb_l1 = 0.0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, params = data['image'], data['params']\n",
    "        if device == 'cuda':\n",
    "            inputs = inputs.to(device)\n",
    "            params = params.to(device)\n",
    "        inputs_ = transform_i(t(inputs))\n",
    "        # loss\n",
    "        loss = criterion(inputs, inputs_)\n",
    "        # pen\n",
    "        c_t.weight = t.conv1.weight\n",
    "        c_i.weight = transform_i.convt1.weight\n",
    "        inner_prod = c_t(t.conv1.weight)\n",
    "        loss += lamb*criterion(inner_prod * mask, zeros)\n",
    "        inner_prod = c_i(transform_i.convt1.weight)\n",
    "        loss += lamb*criterion(inner_prod * mask, zeros)\n",
    "        # smth\n",
    "        loss += lamb_smth*(gradient_pen(t.conv1.weight) + gradient_pen(transform_i.convt1.weight))\n",
    "        # interp\n",
    "        model_t.x_orig = deepcopy(inputs)\n",
    "        inputs_t = t(inputs)\n",
    "        attributer = InputXGradient(model_t)\n",
    "        attributions = attributer.attribute(inputs_t, target=1)\n",
    "        loss += lamb_l1*l1loss(attributions, torch.zeros_like(attributions))\n",
    "        # zero grad\n",
    "        t.zero_grad()\n",
    "        transform_i.zero_grad()\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # Update G\n",
    "        optimizer_t.step()\n",
    "        optimizer_i.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(data_loader.dataset),\n",
    "                       100. * i / len(data_loader), loss.data.item()), end='')\n",
    "            torch.save(t.state_dict(), './models/transform_'  + str(int(lamb)) + '_' + str(int(lamb_smth)) + '_' + str(int(lamb_l1)))\n",
    "            torch.save(transform_i.state_dict(), './models/transform_i_'  + str(int(lamb)) + '_' + str(int(lamb_smth)) + '_' + str(int(lamb_l1)))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss versus training iterations\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz filters\n",
    "viz_filters(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz filters\n",
    "viz_filters(transform_i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
