{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os,sys\n",
    "opj = os.path.join\n",
    "from tqdm import tqdm\n",
    "import acd\n",
    "from copy import deepcopy\n",
    "import torchvision.utils as vutils\n",
    "import models\n",
    "from visualize import *\n",
    "from data import *\n",
    "sys.path.append('../trim')\n",
    "from transforms_torch import transform_bandpass, tensor_t_augment, batch_fftshift2d, batch_ifftshift2d\n",
    "from trim import *\n",
    "from util import *\n",
    "from attributions import *\n",
    "from captum.attr import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_path = './cosmo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "img_size = 256\n",
    "class_num = 1\n",
    "\n",
    "# cosmo dataset\n",
    "transformer = transforms.Compose([ToTensor()])\n",
    "mnu_dataset = MassMapsDataset(opj(data_path, 'cosmological_parameters.txt'),  \n",
    "                              opj(data_path, 'z1_256'),\n",
    "                              transform=transformer)\n",
    "\n",
    "# dataloader\n",
    "data_loader = torch.utils.data.DataLoader(mnu_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# load model\n",
    "model = models.load_model(model_name='resnet18', device=device, data_path=data_path).to(device)\n",
    "model = model.eval()\n",
    "# freeze layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     result = {'y': [], 'pred': []}\n",
    "#     for i in tqdm(range(100)):\n",
    "#         sample = mnu_dataset[i]\n",
    "#         x = sample['image']\n",
    "#         result['y'].append(sample['params'][1].item())\n",
    "#         result['pred'].append(model(x.unsqueeze(0).to(device)).flatten()[1].item())\n",
    "# # print(result)\n",
    "# plt.scatter(result['y'], result['pred'])\n",
    "# plt.xlabel('true param')\n",
    "# plt.ylabel('predicted param')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.convt1 = nn.ConvTranspose2d(64, 1, kernel_size=7, stride=2, padding=3, output_padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.convt1(x)\n",
    "    \n",
    "\n",
    "class Reconstruction(nn.Module):\n",
    "    def __init__(self, model, generator):\n",
    "        super(Reconstruction, self).__init__()\n",
    "        self.conv1 = model.conv1\n",
    "        self.bn1 = model.bn1\n",
    "        self.relu1 = model.relu\n",
    "        self.maxpool1 = model.maxpool\n",
    "        self.maxpool1.return_indices = True\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.convt1 = generator.convt1\n",
    "        \n",
    "        # freeze conv1 and bn1\n",
    "        self.conv1\n",
    "        \n",
    "    def feature_map(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x, ind = self.maxpool1(x)\n",
    "        x = self.unpool1(x, ind, output_size=torch.Size([30, 64, 128, 128]))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_map(x)\n",
    "        return self.convt1(x)\n",
    "    \n",
    "    \n",
    "def gradient_pen(gen_frames, alpha=2):\n",
    "\n",
    "    def gradient(x):\n",
    "        # idea from tf.image.image_gradients(image)\n",
    "        # https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/image_ops_impl.py#L3441-L3512\n",
    "        # x: (b,c,h,w), float32 or float64\n",
    "        # dx, dy: (b,c,h,w)\n",
    "\n",
    "        h_x = x.size()[-2]\n",
    "        w_x = x.size()[-1]\n",
    "        # gradient step=1\n",
    "        left = x\n",
    "        right = F.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n",
    "        top = x\n",
    "        bottom = F.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n",
    "\n",
    "        # dx, dy = torch.abs(right - left), torch.abs(bottom - top)\n",
    "        dx, dy = right - left, bottom - top \n",
    "        # dx will always have zeros in the last column, right-left\n",
    "        # dy will always have zeros in the last row,    bottom-top\n",
    "        dx[:, :, :, -1] = 0\n",
    "        dy[:, :, -1, :] = 0\n",
    "\n",
    "        return dx, dy\n",
    "    \n",
    "    # gradient\n",
    "    gen_dx, gen_dy = gradient(gen_frames)\n",
    "    \n",
    "    # condense into one tensor and avg\n",
    "    return torch.mean(gen_dx ** alpha + gen_dy ** alpha)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "netG = Generator().to(device)\n",
    "# netG.load_state_dict(torch.load('./models/conv_filters_pen'))\n",
    "\n",
    "# prepend model and netG\n",
    "netR = Reconstruction(model, netG).to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Setup Adam optimizers for G\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.001)\n",
    "\n",
    "# mask\n",
    "# mask = torch.ones(64, 64, 1, 1).to(device)\n",
    "# for i in range(64):\n",
    "#     mask[i,i,0,0] = 0\n",
    "    \n",
    "# zeros = torch.zeros(64, 64, 1, 1).to(device)\n",
    "# # conv operator for penalty\n",
    "# c = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=0, bias=False).to(device)\n",
    "\n",
    "# mask\n",
    "padding = 5\n",
    "dim = padding*2+1\n",
    "mask = torch.ones(64, 64, dim, dim).to(device)\n",
    "for i in range(64):\n",
    "    mask[i,i,padding,padding] = 0\n",
    "    \n",
    "zeros = torch.zeros(64, 64, dim, dim).to(device)\n",
    "\n",
    "# conv operator for penalty\n",
    "c = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=padding, bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "Train Epoch: 0 [24000/100000 (24%)]\tLoss: 0.000448"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "lamb = 10000.0\n",
    "lamb_smth = 200.0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, params = data['image'], data['params']\n",
    "        if device == 'cuda':\n",
    "            inputs = inputs.to(device)\n",
    "            params = params.to(device)\n",
    "        inputs_ = netR(inputs)\n",
    "        # loss\n",
    "        loss = criterion(inputs, inputs_)\n",
    "        # pen\n",
    "        c.weight = netG.convt1.weight\n",
    "        inner_prod = c(netG.convt1.weight)\n",
    "        loss += lamb*criterion(inner_prod * mask, zeros)\n",
    "        # smth\n",
    "        loss += lamb_smth*gradient_pen(netG.convt1.weight)\n",
    "        # zero grad\n",
    "        netG.zero_grad()\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(data_loader.dataset),\n",
    "                       100. * i / len(data_loader), loss.data.item()), end='')\n",
    "            torch.save(netG.state_dict(), './models/conv_filters_pen_' + str(int(lamb)) + '_' + str(int(lamb_smth)) \\\n",
    "                                                                              + '_' + str(int(padding)))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss versus training iterations\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz filters\n",
    "viz_filters(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = mnu_dataset[25000]['image'].to(device).unsqueeze(0)\n",
    "viz_im_r(im, netR(im))\n",
    "print(torch.norm(im - netR(im)).item()**2/28**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
